[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cheng-Yuan Wu",
    "section": "",
    "text": "Hello, I’m Cheng-Yuan Wu.\nWelcome to my personal website! I’m currently studying at UC San Diego and working on cool projects in data, analytics, and business strategy.\nYou can find my resume here or connect with me on LinkedIn."
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Cheng-Yuan Wu",
    "section": "",
    "text": "Hello, I’m Cheng-Yuan Wu.\nWelcome to my personal website! I’m currently studying at UC San Diego and working on cool projects in data, analytics, and business strategy.\nYou can find my resume here or connect with me on LinkedIn."
  },
  {
    "objectID": "Resume.html",
    "href": "Resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "hw1_questions.html",
    "href": "hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe study found that announcing a matching grant significantly increased both the likelihood of donation and the average amount given. However, increasing the match ratio—such as from 1:1 to 3:1—did not yield any additional gains in giving. Interestingly, the effectiveness of matching grants also varied by political geography: donors in Republican-leaning (“red”) states were more responsive than those in Democratic-leaning (“blue”) states. These results challenge conventional fundraising wisdom and offer practical insights for designing more effective donation campaigns.\nThis project aims to replicate their findings."
  },
  {
    "objectID": "hw1_questions.html#introduction",
    "href": "hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe study found that announcing a matching grant significantly increased both the likelihood of donation and the average amount given. However, increasing the match ratio—such as from 1:1 to 3:1—did not yield any additional gains in giving. Interestingly, the effectiveness of matching grants also varied by political geography: donors in Republican-leaning (“red”) states were more responsive than those in Democratic-leaning (“blue”) states. These results challenge conventional fundraising wisdom and offer practical insights for designing more effective donation campaigns.\nThis project aims to replicate their findings."
  },
  {
    "objectID": "hw1_questions.html#data",
    "href": "hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nData Description\nThis dataset originates from the field experiment conducted by Karlan and List (2007), in which 50,083 prior donors were sent fundraising letters randomly assigned to different treatments. Each row represents one individual who received a solicitation letter.\n\n\nDataset Overview\n\nTotal observations: 50,083\nUnit of observation: Individual donor\nDesign: Randomized field experiment with control and treatment groups\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\nKey Variables Summary\n\n\n\n\n\n\n\n\nVariable\nMean\nDescription\n\n\n\n\ntreatment\n0.667\nReceived a treatment letter (matching/challenge)\n\n\ncontrol\n0.333\nReceived a standard control letter\n\n\ngave\n0.021\nDonated (binary: 1 if donated, 0 otherwise)\n\n\namount\n0.916\nDonation amount (including 0s for non-donors)\n\n\namountchange\n-52.67\nChange in amount given compared to previous donations\n\n\nhpa\n59.38\nHighest previous contribution\n\n\nltmedmra\n0.494\nIndicator for small prior donors (last gift &lt; $35)\n\n\nyear5\n0.509\nDonor for at least 5 years\n\n\ndormant\n0.523\nAlready donated in 2005\n\n\nfemale\n0.278\nFemale donor\n\n\ncouple\n0.092\nCouple donor\n\n\n\n\n\nTreatment Group Assignment\n\n\n\nVariable\nMean\nDescription\n\n\n\n\nratio2\n0.222\nReceived 2:1 matching treatment\n\n\nratio3\n0.222\nReceived 3:1 matching treatment\n\n\nsize25\n0.167\n$25,000 match threshold\n\n\nsize50\n0.167\n$50,000 match threshold\n\n\nsize100\n0.167\n$100,000 match threshold\n\n\nsizeno\n0.167\nUnstated match threshold\n\n\naskd1\n0.222\nSuggested amount = last donation\n\n\naskd2\n0.222\nSuggested amount = 1.25x last donation\n\n\naskd3\n0.222\nSuggested amount = 1.5x last donation\n\n\n\n\n\nPolitical and Geographic Context\n\n\n\n\n\n\n\n\nVariable\nMean\nDescription\n\n\n\n\nred0\n0.404\nLives in a Republican-leaning (red) state\n\n\nblue0\n0.596\nLives in a Democratic-leaning (blue) state\n\n\nredcty\n0.510\nLives in a red county\n\n\nperbush\n0.489\nState-level vote share for Bush (2004)\n\n\n\n\n\nZip Code Demographics\n\n\n\n\n\n\n\n\nVariable\nMean\nDescription\n\n\n\n\npwhite\n0.820\nProportion of white residents\n\n\npblack\n0.087\nProportion of Black residents\n\n\npage18_39\n0.322\nProportion aged 18–39\n\n\nmedian_hhincome\n$54,816\nMedian household income\n\n\npowner\n0.669\nProportion of homeowners\n\n\npsch_atlstba\n0.392\nProportion with at least a bachelor’s degree\n\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\n\nT-test vs. Linear Regression\nTo verify whether the random assignment was successful, we tested a few non-outcome variables to see if treatment and control groups differ significantly at the 95% confidence level. This helps us confirm whether any observed treatment effects later can be attributed to the intervention itself, not to pre-existing group differences.\nWe tested four variables: - mrm2 (months since last donation) - freq (number of prior donations) - amountchange (change in donation amount) - female (gender)\n\n\n\nHypothesis\nFor each variable, we test:\n\nNull hypothesis (H₀): There is no difference in means between treatment and control groups.\nAlternative hypothesis (H₁): There is a difference in means between the groups.\n\n\n\n\nT-test Results\n\n\n\n\n\n\n\n\n\n\n\nFeature\nMean\nStd\nT-statistic\nP-value\n95% Confidence Interval\n\n\n\n\nmrm2\n13.007\n12.081\n0.119\n0.905\n(-0.211, 0.238)\n\n\nfreq\n8.039\n11.394\n-0.111\n0.912\n(-0.224, 0.200)\n\n\namountchange\n-52.672\n1267.239\n0.527\n0.598\n(-17.216, 29.877)\n\n\nfemale\n0.278\n0.448\n-1.758\n0.079\n(-0.016, 0.001)\n\n\n\n\nAll p-values are above 0.05, so we fail to reject the null hypothesis. There is no statistically significant difference between the treatment and control groups for any of these variables, indicating that random assignment was successful.\n\n\n\n\nT-test Code\n# For 'mrm2' as an example\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\n\ndata = pd.read_stata(\"karlan_list_2007.dta\")\ndf_treatment = data[data['treatment'] == 1]['mrm2'].dropna()\ndf_control = data[data['treatment'] == 0]['mrm2'].dropna()\n\nt_stat, p_val = stats.ttest_ind(df_treatment, df_control, equal_var=True)\n\nprint(f\"T-statistic: {t_stat:.3f}\")\nprint(f\"P-value: {p_val:.4f}\")\n\nmean_diff = df_treatment.mean() - df_control.mean()\nn1, n2 = len(df_treatment), len(df_control)\ns1, s2 = df_treatment.std(ddof=1), df_control.std(ddof=1)\n\nsp = np.sqrt(((n1 - 1)*s1**2 + (n2 - 1)*s2**2) / (n1 + n2 - 2))\nse = sp * np.sqrt(1/n1 + 1/n2)\n\nt_crit = stats.t.ppf(0.975, df=n1 + n2 - 2)\nci_low = mean_diff - t_crit * se\nci_high = mean_diff + t_crit * se\n\nprint(f\"\\nMean Difference: {mean_diff:.3f}\")\nprint(f\"95% Confidence Interval: ({ci_low:.3f}, {ci_high:.3f})\")\n\n\nLinear Regression Validation\nTo confirm the t-test results, we also ran simple linear regressions for each variable using the treatment indicator as the independent variable. This allows us to check whether the coefficient on treatment (i.e., the mean difference between groups) matches the value from the t-test.\n\n\n\nRegression Model\nFor each variable (e.g., mrm2), we estimate the model: \\[\nY_i = \\beta_0 + \\beta_1 \\cdot \\text{treatment}_i + \\epsilon_i\n\\]\nWhere:\n\n\\(Y_i\\) is the outcome variable (e.g., mrm2, freq, etc.)\n\\(\\text{treatment}_i = 1\\) if the observation is in the treatment group, and \\(0\\) otherwise\n\n\\(\\beta_1\\) represents the difference in means between the treatment and control groups\n\n\nIf the coefficient of treatment is not statistically significant, it means there is no difference between the groups, which supports the randomization.\nThe p-value and 95% confidence interval should match the t-test results exactly.\n\n\n\nRegression Code\nimport statsmodels.api as sm\n\n# Prepare data\ndata = pd.read_stata(\"karlan_list_2007.dta\")\ndf_clean = data[['mrm2', 'treatment']].dropna()\n\n# Define X and y\nX = sm.add_constant(df_clean['treatment'])  # Adds intercept\ny = df_clean['mrm2']\n\n# Fit the model\nmodel = sm.OLS(y, X).fit()\n\n# Print regression result\nprint(model.summary())\nFor mrm2: The coefficient for treatment is 0.009, with a p-value of 0.940, which is exactly consistent with the t-test result. The 95% confidence interval also matches.\nSo the treatment group and the control group prove to be randomly selected and have no group differences."
  },
  {
    "objectID": "hw1_questions.html#experimental-results",
    "href": "hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\nThe bar chart below shows the proportion of people who donated in each group.\n\n\n\nDonation Rate by Group\n\n\n\n\nImpact of Treatment on Donation Behavior\nWe tested whether individuals who received a treatment letter (with a matching grant offer) were more likely to make a charitable donation compared to those who received a standard control letter.\n\n\nT-test Code\ndf_treatment = data[data['treatment'] == 1]['gave'].dropna()\ndf_control = data[data['treatment'] == 0]['gave'].dropna()\n\nt_stat, p_val = stats.ttest_ind(df_treatment, df_control, equal_var=True)\n\nprint(f\"T-statistic: {t_stat:.3f}\")\nprint(f\"P-value: {p_val:.4f}\")\n\nmean_diff = df_treatment.mean() - df_control.mean()\nn1, n2 = len(df_treatment), len(df_control)\ns1, s2 = df_treatment.std(ddof=1), df_control.std(ddof=1)\n\nsp = np.sqrt(((n1 - 1)*s1**2 + (n2 - 1)*s2**2) / (n1 + n2 - 2))\nse = sp * np.sqrt(1/n1 + 1/n2)\n\nt_crit = stats.t.ppf(0.975, df=n1 + n2 - 2)\nci_low = mean_diff - t_crit * se\nci_high = mean_diff + t_crit * se\n\nprint(f\"\\nMean Difference: {mean_diff:.3f}\")\nprint(f\"95% Confidence Interval: ({ci_low:.3f}, {ci_high:.3f})\")\nA t-test comparing the proportion of donors between the two groups revealed a statistically significant difference: individuals in the treatment group were more likely to donate. The mean difference in donation rates was 0.004, with a t-statistic of 3.101 and a p-value of 0.0019. The 95% confidence interval for the difference was (0.002, 0.007), which does not include zero — providing strong evidence that the treatment had a real effect.\nTo confirm this result, we ran a bivariate linear regression where the outcome variable was a binary indicator of whether a donation was made.\n\n\nRegression Code\ndf_clean = data[['gave', 'treatment']].dropna()\nX = sm.add_constant(df_clean['treatment']) \ny = df_clean['gave']\nmodel = sm.OLS(y, X).fit()\n\nprint(model.summary())\nThe coefficient on the treatment variable was 0.0042, with a p-value of 0.002, and the 95% confidence interval was also (0.002, 0.007). This perfectly aligns with the t-test results and confirms that the treatment increased the likelihood of giving.\nThis result supports the idea that including a matching grant offer in a donation appeal can meaningfully influence behavior. Even though the financial amount offered as a match was the same, simply presenting the opportunity to have one’s donation matched significantly increased the chance that someone would donate at all.\nIn behavioral terms, this suggests that people respond to cues of increased impact — like knowing their donation will be matched. It may enhance the perceived effectiveness or social validation of their gift. This finding highlights how small changes in how we ask for donations can significantly affect participation rates.\n\n\nProbit Regression Analysis\nTo better understand the impact of the treatment on donation behavior, we estimated a probit regression where the binary outcome variable was whether or not a donation was made (gave), and the explanatory variable was the assignment to the treatment group.\n\n\nCode\ndf_clean = data[['gave', 'treatment']].dropna()\n\nX = sm.add_constant(df_clean['treatment'])\ny = df_clean['gave']\n\nprobit_model = sm.Probit(y, X).fit()\nprint(probit_model.summary())\nThe estimated coefficient on the treatment variable is 0.0868, with a z-statistic of 3.113 and a p-value of 0.002, indicating that the effect is statistically significant at the 1% level. The 95% confidence interval for the coefficient is (0.032, 0.141), which excludes zero.\nThis result replicates Table 3, Column 1 of Karlan & List (2007), confirming that individuals in the treatment group were significantly more likely to make a charitable donation than those in the control group.\nThe positive and significant coefficient on treatment suggests that receiving a fundraising letter with a matching grant offer makes people more likely to donate, even after controlling for random assignment through a nonlinear probability model.\nIn simpler terms, this shows that human behavior is sensitive to perceived impact. When people are told that their donation will be matched by someone else, they are more motivated to act. This finding reinforces the behavioral insight that the way a request is framed — even without changing the actual cost — can meaningfully affect decision-making.\nThis has real-world implications for how nonprofits design their appeals: adding a matching offer not only increases donation amounts, but also boosts the likelihood that people will give at all.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\nWe test whether higher match ratios (2:1, 3:1) increase the probability of donation compared to a baseline 1:1 match. The following T-tests compare donation rates between these match conditions.\n\n\nT-test Code\n\n# Filter for treatment group with valid ratio and donation outcome\ndf_ratio = data[(data['treatment'] == 1) & (data['ratio'].notnull()) & (data['gave'].notnull())]\n\n# Split by match ratio\ngave_11 = df_ratio[df_ratio['ratio'] == 1]['gave'].dropna()\ngave_21 = df_ratio[df_ratio['ratio'] == 2]['gave'].dropna()\ngave_31 = df_ratio[df_ratio['ratio'] == 3]['gave'].dropna()\n\n# Donation rates\nmean_11 = gave_11.mean()\nmean_21 = gave_21.mean()\nmean_31 = gave_31.mean()\n\nprint(\"Donation Rates:\")\nprint(f\"1:1  = {mean_11:.4f}\")\nprint(f\"2:1  = {mean_21:.4f}\")\nprint(f\"3:1  = {mean_31:.4f}\")\n\n# T-tests\nprint(\"\\nT-test Results:\")\nt_21, p_21 = stats.ttest_ind(gave_21, gave_11, equal_var=False)\nt_31, p_31 = stats.ttest_ind(gave_31, gave_11, equal_var=False)\nt_32, p_32 = stats.ttest_ind(gave_31, gave_21, equal_var=False)\n\nprint(f\"2:1 vs 1:1 → T = {t_21:.3f}, p = {p_21:.4f}\")\nprint(f\"3:1 vs 1:1 → T = {t_31:.3f}, p = {p_31:.4f}\")\nprint(f\"3:1 vs 2:1 → T = {t_32:.3f}, p = {p_32:.4f}\")\n\nT-test Results:\n\n2:1 vs 1:1 → T = 0.965, p = 0.3345\n3:1 vs 1:1 → T = 1.015, p = 0.3101\n3:1 vs 2:1 → T = 0.050, p = 0.9600\n\n\nAlthough the donation rates appear slightly higher for the 2:1 and 3:1 match offers (2.26% and 2.27%) compared to the 1:1 match (2.07%), the differences are not statistically significant. All p-values are far above the 0.05 threshold, meaning we cannot reject the null hypothesis of equal donation probabilities between match ratio groups.\nWe now assess the effect of different match ratios on donation behavior using a linear regression model. We create dummy variables for 2:1 and 3:1 match ratios, using 1:1 as the reference group.\n\n\nRegression Code\n\n# Filter treatment group and prepare ratio dummies\ndf_ratio = data[(data['treatment'] == 1) & (data['ratio'].isin([1,2,3])) & (data['gave'].notnull())]\ndf_ratio['ratio2'] = (df_ratio['ratio'] == 2).astype(int)\ndf_ratio['ratio3'] = (df_ratio['ratio'] == 3).astype(int)\n\n# Run regression\nX = sm.add_constant(df_ratio[['ratio2', 'ratio3']])\ny = df_ratio['gave']\nmodel = sm.OLS(y, X).fit()\nprint(model.summary())\n\nRegression Results Summary:\n\nIntercept (baseline 1:1 match): 0.0207\nCoefficient for 2:1 match: +0.0019, p = 0.338\nCoefficient for 3:1 match: +0.0020, p = 0.313\n\n\nThis regression confirms the earlier t-test findings: although donation rates appear slightly higher for 2:1 and 3:1 match ratios compared to 1:1, the differences are not statistically significant. Both p-values are above 0.3, and the confidence intervals include zero, suggesting no meaningful increase in donation probability from increasing the match ratio.\nThis matches the earlier t-test results and supports the paper’s finding.\nWe also compare donation rates across match ratios in two ways:\n\nDirectly from the data — by calculating group means\n\nFrom the regression model — by examining the estimated coefficients\n\nBoth approaches provide estimates of how 2:1 and 3:1 match ratios compare to the 1:1 baseline.\n\n\nCode\n# Directly from data\ngave_11 = df_ratio[df_ratio['ratio'] == 1]['gave'].mean()\ngave_21 = df_ratio[df_ratio['ratio'] == 2]['gave'].mean()\ngave_31 = df_ratio[df_ratio['ratio'] == 3]['gave'].mean()\n\nprint(\"Direct from data:\")\nprint(f\"2:1 - 1:1 = {gave_21 - gave_11:.4f}\")\nprint(f\"3:1 - 1:1 = {gave_31 - gave_11:.4f}\")\nprint(f\"3:1 - 2:1 = {gave_31 - gave_21:.4f}\")\n\n# From regression coefficients\nb2 = model.params['ratio2']\nb3 = model.params['ratio3']\n\nprint(\"\\nFrom regression coefficients:\")\nprint(f\"2:1 - 1:1 = {b2:.4f}\")\nprint(f\"3:1 - 1:1 = {b3:.4f}\")\nprint(f\"3:1 - 2:1 = {b3 - b2:.4f}\")\n\nDirect from data: Response rate difference (2:1 - 1:1): 0.0019\nDirect from data: Response rate difference (3:1 - 1:1): 0.0020\nDirect from data: Response rate difference (3:1 - 2:1): 0.0001\nFrom regression: Response rate difference (2:1 - 1:1): 0.0019\nFrom regression: Response rate difference (3:1 - 1:1): 0.0020\nFrom regression: Response rate difference (3:1 - 2:1): 0.0001\n\nThese results are consistent whether calculated directly from the raw data or from the estimated regression coefficients.\nSuch small differences, combined with the non-significant p-values seen earlier, indicate that increasing the match ratio does not lead to a meaningful increase in the likelihood of donation.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\nIn addition to increasing the likelihood of giving, does the treatment also lead to larger donation amounts among donors?\nWe conduct a t-test comparing the donation amounts (amount) between the treatment and control groups.\n\n\nT-test Code\n# T-test comparing donation amounts\namount_t = data[data['treatment'] == 1]['amount'].dropna()\namount_c = data[data['treatment'] == 0]['amount'].dropna()\n\nfrom scipy import stats\nt_stat, p_val = stats.ttest_ind(amount_t, amount_c, equal_var=False)\n\nprint(f\"T-statistic: {t_stat:.3f}\")\nprint(f\"P-value: {p_val:.4f}\")\nprint(f\"Mean difference: {amount_t.mean() - amount_c.mean():.3f}\")\n\nResults\n\nT-statistic: 1.918\nP-value: 0.0551\nMean difference: $0.154\n\n\nWhile the treatment group donated an average of $0.154 more than the control group, the difference is not statistically significant at the 5% level. The p-value of 0.0551 is just above the standard cutoff of 0.05.\nThis suggests a potential positive effect of treatment on donation amount, but the evidence is not strong enough to make a definitive conclusion.\nNow we restrict the sample to only those individuals who made a donation (amount &gt; 0) and examine whether assignment to the treatment group influenced the amount donated, conditional on giving.\nThis analysis estimates the conditional average treatment effect (CATE) on donation size.\n\n\nRegression Code\n# Filter: only donors\ndf_positive = data[(data['amount'] &gt; 0) & data['treatment'].notnull()]\n\n# Run regression\nX = sm.add_constant(df_positive['treatment'])\ny = df_positive['amount']\nmodel = sm.OLS(y, X).fit()\n\nprint(model.summary())\n\nResults\n\nIntercept (control group mean donation): $45.54\nTreatment coefficient: -1.668, p = 0.561\n\n\nAmong those who donated, individuals in the treatment group gave $1.67 less on average than those in the control group. However, this difference is not statistically significant (p = 0.561), and the confidence interval includes both negative and positive values (-7.31 to +3.97). This means that while the direction of the estimate is slightly negative, we have no evidence to conclude that the treatment caused people to give more or less, once they had already decided to donate.\nSo we do two bar chart to show the distribution directly. The histograms below display the distribution of donation amounts among individuals who made a donation, separately for the treatment and control groups. Each plot includes a red dashed line indicating the sample mean.\n\n\n\nDonation Amounts\n\n\nFrom the plots, we observe that:\n\nBoth groups are highly right-skewed: most donors give between $10–$50, but a small number give substantially more (some over $200).\nThe control group has a slightly higher mean donation ($45.54) compared to the treatment group ($43.87).\nThe two distributions are fairly similar in shape, with the treatment group having a marginally heavier tail but not substantially so.\n\nThis observation is consistent with our previous regression analysis (run on donors only), where the treatment group donated $1.67 less on average, but the difference was not statistically significant (p = 0.561).\nWhile the treatment had a positive effect on donation likelihood, it did not lead to higher donation amounts among those who chose to give. In fact, the treatment group donated slightly less on average.\nThis reinforces the interpretation that the matching grant offer may influence whether someone donates, but does not significantly affect how much they donate, once they decide to give.\n\n\nSimulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\n\nLaw of Large Numbers\nNext we want to simulate the cumulative average of differences in donation amounts between treatment and control groups.\nThis helps us visualize how a sample average stabilizes as the number of samples increases.\n\n\n\nCumulative Average of Donation Differences\n\n\n\n\n\nSimulation Code\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Filter for positive donations\ncontrol = data[(data['treatment'] == 0) & (data['amount'] &gt; 0)]['amount'].values\ntreatment = data[(data['treatment'] == 1) & (data['amount'] &gt; 0)]['amount'].values\n\n# Simulate draws\nnp.random.seed(42)\ndraws_control = np.random.choice(control, 100000, replace=True)\ndraws_treatment = np.random.choice(treatment, 10000, replace=True)\n\n# Calculate differences\ndifferences = draws_treatment - draws_control[:10000]\n\n# Compute cumulative average\ncumulative_avg = np.cumsum(differences) / np.arange(1, len(differences) + 1)\n\n# Plot\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, label='Cumulative Average of Differences', color='steelblue')\nplt.axhline(np.mean(treatment) - np.mean(control), color='red', linestyle='--', label='True Mean Difference')\nplt.title('Cumulative Average of Donation Differences (Treatment - Control)')\nplt.xlabel('Number of Simulated Pairs')\nplt.ylabel('Cumulative Average Difference ($)')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\nThis simulation illustrates how sample averages behave as we increase the number of observations. Initially, the cumulative average of differences is highly unstable, with large fluctuations. But as more pairs are sampled, the line converges toward the true mean difference, indicated by the red dashed line.\nThis is a direct demonstration of the Law of Large Numbers: as the number of samples increases, the sample mean gets closer to the population mean.\nIn this case, the simulation confirms that although there is considerable variation with small samples, the overall average difference in donations between the treatment and control groups stabilizes close to the true effect — which in our case is slightly negative.\n\n\nCentral Limit Theorem\nTo understand how sample size affects the precision and stability of estimated treatment effects, we simulate four sets of experiments with different sample sizes.\nFor each sample size (50, 200, 500, 1000), we:\n\nDraw n random samples from both the treatment and control distributions\nCompute the average donation difference (treatment - control)\nRepeat this process 1000 times\nPlot the distribution (histogram) of the 1000 average differences\n\n\n\n\nDifferent Sample Size Simulation\n\n\n\n\nSimulation Code\n\n# Filter: only positive donation amounts\ncontrol = data[(data['treatment'] == 0) & (data['amount'] &gt; 0)]['amount'].values\ntreatment = data[(data['treatment'] == 1) & (data['amount'] &gt; 0)]['amount'].values\n\nsample_sizes = [50, 200, 500, 1000]\nn_simulations = 1000\n\nplt.figure(figsize=(20, 4))\nfor i, size in enumerate(sample_sizes):\n    diffs = []\n    for _ in range(n_simulations):\n        c = np.random.choice(control, size, replace=True)\n        t = np.random.choice(treatment, size, replace=True)\n        diffs.append(np.mean(t) - np.mean(c))\n\n    plt.subplot(1, 4, i + 1)\n    plt.hist(diffs, bins=30, color='skyblue', edgecolor='black')\n    plt.axvline(x=0, color='red', linestyle='--', label='Zero Line')\n    plt.title(f'Sample size = {size}')\n    plt.xlabel('Mean Difference ($)')\n    plt.ylabel('Frequency')\n    plt.legend()\n\nplt.tight_layout()\nplt.show()\nAs sample size increases: - The distribution of estimated treatment effects becomes narrower and more concentrated - At small sample sizes (like 50), the distribution is wide, and zero is near the center, indicating a high degree of uncertainty - At larger sample sizes (like 1000), the distribution is tighter, and zero lies closer to the edge of the distribution, suggesting a more stable and possibly significant treatment effect\nThis simulation highlights how larger sample sizes reduce variance and help us better detect true effects.\nLarger samples lead to more precise and stable estimates of the treatment effect"
  },
  {
    "objectID": "hw1_questions.html#simulation-experiment",
    "href": "hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nNext we want to simulate the cumulative average of differences in donation amounts between treatment and control groups.\nThis helps us visualize how a sample average stabilizes as the number of samples increases.\n\n\n\nSimulation Code\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Filter for positive donations\ncontrol = data[(data['treatment'] == 0) & (data['amount'] &gt; 0)]['amount'].values\ntreatment = data[(data['treatment'] == 1) & (data['amount'] &gt; 0)]['amount'].values\n\n# Simulate draws\nnp.random.seed(42)\ndraws_control = np.random.choice(control, 100000, replace=True)\ndraws_treatment = np.random.choice(treatment, 10000, replace=True)\n\n# Calculate differences\ndifferences = draws_treatment - draws_control[:10000]\n\n# Compute cumulative average\ncumulative_avg = np.cumsum(differences) / np.arange(1, len(differences) + 1)\n\n# Plot\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, label='Cumulative Average of Differences', color='steelblue')\nplt.axhline(np.mean(treatment) - np.mean(control), color='red', linestyle='--', label='True Mean Difference')\nplt.title('Cumulative Average of Donation Differences (Treatment - Control)')\nplt.xlabel('Number of Simulated Pairs')\nplt.ylabel('Cumulative Average Difference ($)')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\nThis simulation illustrates how sample averages behave as we increase the number of observations. Initially, the cumulative average of differences is highly unstable, with large fluctuations. But as more pairs are sampled, the line converges toward the true mean difference, indicated by the red dashed line.\nThis is a direct demonstration of the Law of Large Numbers: as the number of samples increases, the sample mean gets closer to the population mean.\nIn this case, the simulation confirms that although there is considerable variation with small samples, the overall average difference in donations between the treatment and control groups stabilizes close to the true effect — which in our case is slightly negative.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”"
  },
  {
    "objectID": "data_hw1.html",
    "href": "data_hw1.html",
    "title": "Cheng-Yuan Wu's Website",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\n\n\ndata = pd.read_stata('karlan_list_2007.dta')\ndata.head()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\n\n\n\ndf = data.describe(include='all')\ndf\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\ncount\n50083.000000\n50083.000000\n50083\n50083.000000\n50083.000000\n50083\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n...\n49978.000000\n49978.000000\n48217.000000\n48047.000000\n48217.000000\n48221.000000\n48209.000000\n48214.000000\n48215.000000\n48217.000000\n\n\nunique\nNaN\nNaN\n4\nNaN\nNaN\n5\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\ntop\nNaN\nNaN\nControl\nNaN\nNaN\nControl\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nfreq\nNaN\nNaN\n16687\nNaN\nNaN\n16687\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nmean\n0.666813\n0.333187\nNaN\n0.222311\n0.222211\nNaN\n0.166723\n0.166623\n0.166723\n0.166743\n...\n0.510245\n0.488715\n0.819599\n0.086710\n0.321694\n2.429012\n54815.700533\n0.669418\n0.391661\n0.871968\n\n\nstd\n0.471357\n0.471357\nNaN\n0.415803\n0.415736\nNaN\n0.372732\n0.372643\n0.372732\n0.372750\n...\n0.499900\n0.499878\n0.168561\n0.135868\n0.103039\n0.378115\n22027.316665\n0.193405\n0.186599\n0.258654\n\n\nmin\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.009418\n0.000000\n0.000000\n0.000000\n5000.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.755845\n0.014729\n0.258311\n2.210000\n39181.000000\n0.560222\n0.235647\n0.884929\n\n\n50%\n1.000000\n0.000000\nNaN\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n0.000000\n0.872797\n0.036554\n0.305534\n2.440000\n50673.000000\n0.712296\n0.373744\n1.000000\n\n\n75%\n1.000000\n1.000000\nNaN\n0.000000\n0.000000\nNaN\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n1.000000\n0.938827\n0.090882\n0.369132\n2.660000\n66005.000000\n0.816798\n0.530036\n1.000000\n\n\nmax\n1.000000\n1.000000\nNaN\n1.000000\n1.000000\nNaN\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n0.989622\n0.997544\n5.270000\n200001.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n11 rows × 51 columns\n\n\n\n\ndf['amount']\n\ncount     50083.000000\nunique             NaN\ntop                NaN\nfreq               NaN\nmean          0.915694\nstd           8.709199\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           0.000000\nmax         400.000000\nName: amount, dtype: float64\n\n\n\nfrom scipy import stats\n# for mrm2\ndf_treatment = data[data['treatment'] == 1]['mrm2'].dropna()\ndf_control = data[data['treatment'] == 0]['mrm2'].dropna()\n\nt_stat, p_val = stats.ttest_ind(df_treatment, df_control, equal_var=True)\n\nprint(f\"T-statistic: {t_stat:.3f}\")\nprint(f\"P-value: {p_val:.4f}\")\n\nT-statistic: 0.119\nP-value: 0.9049\n\n\n\nimport numpy as np\n\nmean_diff = df_treatment.mean() - df_control.mean()\nn1, n2 = len(df_treatment), len(df_control)\ns1, s2 = df_treatment.std(ddof=1), df_control.std(ddof=1)\n\nsp = np.sqrt(((n1 - 1)*s1**2 + (n2 - 1)*s2**2) / (n1 + n2 - 2))\nse = sp * np.sqrt(1/n1 + 1/n2)\n\nt_crit = stats.t.ppf(0.975, df=n1 + n2 - 2)\nci_low = mean_diff - t_crit * se\nci_high = mean_diff + t_crit * se\n\nprint(f\"\\nMean Difference: {mean_diff:.3f}\")\nprint(f\"95% Confidence Interval: ({ci_low:.3f}, {ci_high:.3f})\")\n\n\nMean Difference: 0.014\n95% Confidence Interval: (-0.211, 0.238)\n\n\n\nimport statsmodels.api as sm\ndf_clean = data[['mrm2', 'treatment']].dropna()\nX = sm.add_constant(df_clean['treatment']) \ny = df_clean['mrm2']\nmodel = sm.OLS(y, X).fit()\n\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   mrm2   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                   0.01428\nDate:                Tue, 22 Apr 2025   Prob (F-statistic):              0.905\nTime:                        15:11:15   Log-Likelihood:            -1.9585e+05\nNo. Observations:               50082   AIC:                         3.917e+05\nDf Residuals:                   50080   BIC:                         3.917e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         12.9981      0.094    138.979      0.000      12.815      13.181\ntreatment      0.0137      0.115      0.119      0.905      -0.211       0.238\n==============================================================================\nOmnibus:                     8031.352   Durbin-Watson:                   2.004\nProb(Omnibus):                  0.000   Jarque-Bera (JB):            12471.135\nSkew:                           1.163   Prob(JB):                         0.00\nKurtosis:                       3.751   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n# for freq\ndf_treatment = data[data['treatment'] == 1]['freq'].dropna()\ndf_control = data[data['treatment'] == 0]['freq'].dropna()\n\nt_stat, p_val = stats.ttest_ind(df_treatment, df_control, equal_var=True)\n\nprint(f\"T-statistic: {t_stat:.3f}\")\nprint(f\"P-value: {p_val:.4f}\")\n\nT-statistic: -0.111\nP-value: 0.9117\n\n\n\ndf['freq']\n\ncount     50083.000000\nunique             NaN\ntop                NaN\nfreq               NaN\nmean          8.039355\nstd          11.394454\nmin           0.000000\n25%           2.000000\n50%           4.000000\n75%          10.000000\nmax         218.000000\nName: freq, dtype: float64\n\n\n\nimport numpy as np\n\n# 計算平均差\nmean_diff = df_treatment.mean() - df_control.mean()\n\n# 樣本數與標準差\nn1, n2 = len(df_treatment), len(df_control)\ns1, s2 = df_treatment.std(ddof=1), df_control.std(ddof=1)\n\n# 合併標準差（pooled standard deviation）\nsp = np.sqrt(((n1 - 1)*s1**2 + (n2 - 1)*s2**2) / (n1 + n2 - 2))\n\n# 標準誤\nse = sp * np.sqrt(1/n1 + 1/n2)\n\n# 95% 信賴區間\nt_crit = stats.t.ppf(0.975, df=n1 + n2 - 2)\nci_low = mean_diff - t_crit * se\nci_high = mean_diff + t_crit * se\n\nprint(f\"\\nMean Difference: {mean_diff:.3f}\")\nprint(f\"95% Confidence Interval: ({ci_low:.3f}, {ci_high:.3f})\")\n\n\nMean Difference: -0.012\n95% Confidence Interval: (-0.224, 0.200)\n\n\n\ndf_clean = data[['freq', 'treatment']].dropna()\n# 加入常數項（intercept）\nX = sm.add_constant(df_clean['treatment'])  # 會產生兩個欄位：常數 + treatment\ny = df_clean['freq']\n# 執行 OLS 線性回歸\nmodel = sm.OLS(y, X).fit()\n\n# 印出完整結果\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   freq   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                   0.01230\nDate:                Tue, 22 Apr 2025   Prob (F-statistic):              0.912\nTime:                        17:58:28   Log-Likelihood:            -1.9292e+05\nNo. Observations:               50083   AIC:                         3.858e+05\nDf Residuals:                   50081   BIC:                         3.859e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          8.0473      0.088     91.231      0.000       7.874       8.220\ntreatment     -0.0120      0.108     -0.111      0.912      -0.224       0.200\n==============================================================================\nOmnibus:                    49107.114   Durbin-Watson:                   2.016\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          3644795.393\nSkew:                           4.707   Prob(JB):                         0.00\nKurtosis:                      43.718   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n# for amountchange\ndf_treatment = data[data['treatment'] == 1]['amountchange'].dropna()\ndf_control = data[data['treatment'] == 0]['amountchange'].dropna()\n\nt_stat, p_val = stats.ttest_ind(df_treatment, df_control, equal_var=True)\n\nprint(f\"T-statistic: {t_stat:.3f}\")\nprint(f\"P-value: {p_val:.4f}\")\n\nT-statistic: 0.527\nP-value: 0.5982\n\n\n\nimport numpy as np\n\n# 計算平均差\nmean_diff = df_treatment.mean() - df_control.mean()\n\n# 樣本數與標準差\nn1, n2 = len(df_treatment), len(df_control)\ns1, s2 = df_treatment.std(ddof=1), df_control.std(ddof=1)\n\n# 合併標準差（pooled standard deviation）\nsp = np.sqrt(((n1 - 1)*s1**2 + (n2 - 1)*s2**2) / (n1 + n2 - 2))\n\n# 標準誤\nse = sp * np.sqrt(1/n1 + 1/n2)\n\n# 95% 信賴區間\nt_crit = stats.t.ppf(0.975, df=n1 + n2 - 2)\nci_low = mean_diff - t_crit * se\nci_high = mean_diff + t_crit * se\n\nprint(f\"\\nMean Difference: {mean_diff:.3f}\")\nprint(f\"95% Confidence Interval: ({ci_low:.3f}, {ci_high:.3f})\")\n\n\nMean Difference: 6.331\n95% Confidence Interval: (-17.216, 29.877)\n\n\n\ndf['amountchange']\n\ncount      50083.000000\nunique              NaN\ntop                 NaN\nfreq                NaN\nmean         -52.672016\nstd         1267.238647\nmin      -200412.125000\n25%          -50.000000\n50%          -30.000000\n75%          -25.000000\nmax          275.000000\nName: amountchange, dtype: float64\n\n\n\n# for female\nimport pandas as pd\nimport numpy as np\n\ndf_treatment = data[data['treatment'] == 1]['female'].dropna()\ndf_control = data[data['treatment'] == 0]['female'].dropna()\n\nt_stat, p_val = stats.ttest_ind(df_treatment, df_control, equal_var=True)\n\nprint(f\"T-statistic: {t_stat:.3f}\")\nprint(f\"P-value: {p_val:.4f}\")\n\nmean_diff = df_treatment.mean() - df_control.mean()\nn1, n2 = len(df_treatment), len(df_control)\ns1, s2 = df_treatment.std(ddof=1), df_control.std(ddof=1)\n\nsp = np.sqrt(((n1 - 1)*s1**2 + (n2 - 1)*s2**2) / (n1 + n2 - 2))\nse = sp * np.sqrt(1/n1 + 1/n2)\n\nt_crit = stats.t.ppf(0.975, df=n1 + n2 - 2)\nci_low = mean_diff - t_crit * se\nci_high = mean_diff + t_crit * se\n\nprint(f\"\\nMean Difference: {mean_diff:.3f}\")\nprint(f\"95% Confidence Interval: ({ci_low:.3f}, {ci_high:.3f})\")\n\nT-statistic: -1.758\nP-value: 0.0787\n\nMean Difference: -0.008\n95% Confidence Interval: (-0.016, 0.001)\n\n\n\ndf['female']\n\ncount     48972.000000\nunique             NaN\ntop                NaN\nfreq               NaN\nmean          0.277669\nstd           0.447854\nmin           0.000000\n25%           0.000000\n50%           0.000000\n75%           1.000000\nmax           1.000000\nName: female, dtype: float64\n\n\n\nimport matplotlib.pyplot as plt\n\ngrouped = data.groupby('treatment')['gave'].mean()\n\ngrouped.index = ['Control', 'Treatment']\n\nplt.figure(figsize=(6, 4))\nplt.bar(grouped.index, grouped.values, color=[\"gray\", \"steelblue\"])\nplt.ylabel('Proportion Donated')\nplt.title('Donation Rate by Group')\nplt.ylim(0, 0.03)  # 因為捐款率很低，設定 y 軸比較清楚\nplt.grid(axis='y', linestyle='--', alpha=0.5)\nplt.show()\n\n\n\n\n\n\n\n\n\n# for whether they donate or not\nimport pandas as pd\nimport numpy as np\n\ndf_treatment = data[data['treatment'] == 1]['gave'].dropna()\ndf_control = data[data['treatment'] == 0]['gave'].dropna()\n\nt_stat, p_val = stats.ttest_ind(df_treatment, df_control, equal_var=True)\n\nprint(f\"T-statistic: {t_stat:.3f}\")\nprint(f\"P-value: {p_val:.4f}\")\n\nmean_diff = df_treatment.mean() - df_control.mean()\nn1, n2 = len(df_treatment), len(df_control)\ns1, s2 = df_treatment.std(ddof=1), df_control.std(ddof=1)\n\nsp = np.sqrt(((n1 - 1)*s1**2 + (n2 - 1)*s2**2) / (n1 + n2 - 2))\nse = sp * np.sqrt(1/n1 + 1/n2)\n\nt_crit = stats.t.ppf(0.975, df=n1 + n2 - 2)\nci_low = mean_diff - t_crit * se\nci_high = mean_diff + t_crit * se\n\nprint(f\"\\nMean Difference: {mean_diff:.3f}\")\nprint(f\"95% Confidence Interval: ({ci_low:.3f}, {ci_high:.3f})\")\n\nT-statistic: 3.101\nP-value: 0.0019\n\nMean Difference: 0.004\n95% Confidence Interval: (0.002, 0.007)\n\n\n\ndf_clean = data[['gave', 'treatment']].dropna()\n# 加入常數項（intercept）\nX = sm.add_constant(df_clean['treatment'])  # 會產生兩個欄位：常數 + treatment\ny = df_clean['gave']\n# 執行 OLS 線性回歸\nmodel = sm.OLS(y, X).fit()\n\n# 印出完整結果\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     9.618\nDate:                Tue, 22 Apr 2025   Prob (F-statistic):            0.00193\nTime:                        19:56:19   Log-Likelihood:                 26630.\nNo. Observations:               50083   AIC:                        -5.326e+04\nDf Residuals:                   50081   BIC:                        -5.324e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.0179      0.001     16.225      0.000       0.016       0.020\ntreatment      0.0042      0.001      3.101      0.002       0.002       0.007\n==============================================================================\nOmnibus:                    59814.280   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\nSkew:                           6.740   Prob(JB):                         0.00\nKurtosis:                      46.440   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\nimport pandas as pd\nimport statsmodels.api as sm\n\ndf_clean = data[['gave', 'treatment']].dropna()\n\nX = sm.add_constant(df_clean['treatment'])\ny = df_clean['gave']\n\nprobit_model = sm.Probit(y, X).fit()\nprint(probit_model.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Tue, 22 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        20:25:33   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\n\ndata\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.000000\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.000000\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.000000\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.000000\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n50078\n1\n0\n1\n0\n0\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.872797\n0.089959\n0.257265\n2.13\n45047.0\n0.771316\n0.263744\n1.000000\n\n\n50079\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.688262\n0.108889\n0.288792\n2.67\n74655.0\n0.741931\n0.586466\n1.000000\n\n\n50080\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\n0.900000\n0.021311\n0.178689\n2.36\n26667.0\n0.778689\n0.107930\n0.000000\n\n\n50081\n1\n0\n3\n0\n1\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.917206\n0.008257\n0.225619\n2.57\n39530.0\n0.733988\n0.184768\n0.634903\n\n\n50082\n1\n0\n3\n0\n1\n$25,000\n1\n0\n0\n0\n...\n0.0\n1.0\n0.530023\n0.074112\n0.340698\n3.70\n48744.0\n0.717843\n0.127941\n0.994181\n\n\n\n\n50083 rows × 51 columns\n\n\n\n\ndf_ratio = data[(data['treatment'] == 1) & (data['ratio'].notnull()) & (data['gave'].notnull())]\n\ngave_11 = df_ratio[df_ratio['ratio'] == 1]['gave'].dropna()\ngave_21 = df_ratio[df_ratio['ratio'] == 2]['gave'].dropna()\ngave_31 = df_ratio[df_ratio['ratio'] == 3]['gave'].dropna()\n\n# 比較各組平均捐款率\nmean_11 = gave_11.mean()\nmean_21 = gave_21.mean()\nmean_31 = gave_31.mean()\n\nprint(\"Donation Rates:\")\nprint(f\"1:1  = {mean_11:.4f}\")\nprint(f\"2:1  = {mean_21:.4f}\")\nprint(f\"3:1  = {mean_31:.4f}\")\n\n# T-tests\nprint(\"\\nT-test Results:\")\nt_21, p_21 = stats.ttest_ind(gave_21, gave_11, equal_var=False)\nt_31, p_31 = stats.ttest_ind(gave_31, gave_11, equal_var=False)\nt_32, p_32 = stats.ttest_ind(gave_31, gave_21, equal_var=False)\n\nprint(f\"2:1 vs 1:1 → T = {t_21:.3f}, p = {p_21:.4f}\")\nprint(f\"3:1 vs 1:1 → T = {t_31:.3f}, p = {p_31:.4f}\")\nprint(f\"3:1 vs 2:1 → T = {t_32:.3f}, p = {p_32:.4f}\")\n\nDonation Rates:\n1:1  = 0.0207\n2:1  = 0.0226\n3:1  = 0.0227\n\nT-test Results:\n2:1 vs 1:1 → T = 0.965, p = 0.3345\n3:1 vs 1:1 → T = 1.015, p = 0.3101\n3:1 vs 2:1 → T = 0.050, p = 0.9600\n\n\n\ndf_ratio = data[(data['treatment'] == 1) & (data['ratio'].isin([1,2,3])) & (data['gave'].notnull())]\n\ndf_ratio['ratio2'] = (df_ratio['ratio'] == 2).astype(int)\ndf_ratio['ratio3'] = (df_ratio['ratio'] == 3).astype(int)\nX = sm.add_constant(df_ratio[['ratio2', 'ratio3']])\ny = df_ratio['gave']\nmodel = sm.OLS(y, X).fit()\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.6454\nDate:                Tue, 22 Apr 2025   Prob (F-statistic):              0.524\nTime:                        23:39:57   Log-Likelihood:                 16688.\nNo. Observations:               33396   AIC:                        -3.337e+04\nDf Residuals:                   33393   BIC:                        -3.334e+04\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.0207      0.001     14.912      0.000       0.018       0.023\nratio2         0.0019      0.002      0.958      0.338      -0.002       0.006\nratio3         0.0020      0.002      1.008      0.313      -0.002       0.006\n==============================================================================\nOmnibus:                    38963.957   Durbin-Watson:                   1.995\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          2506478.937\nSkew:                           6.511   Prob(JB):                         0.00\nKurtosis:                      43.394   Cond. No.                         3.73\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n/var/folders/4_/b_ln9nlx3j19x_2nmv9t3rd40000gn/T/ipykernel_56870/1714721735.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_ratio['ratio2'] = (df_ratio['ratio'] == 2).astype(int)\n/var/folders/4_/b_ln9nlx3j19x_2nmv9t3rd40000gn/T/ipykernel_56870/1714721735.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_ratio['ratio3'] = (df_ratio['ratio'] == 3).astype(int)\n\n\n\n# directly from data\ngave_11 = df_ratio[df_ratio['ratio'] == 1]['gave'].mean()\ngave_21 = df_ratio[df_ratio['ratio'] == 2]['gave'].mean()\ngave_31 = df_ratio[df_ratio['ratio'] == 3]['gave'].mean()\n\n# 算差值\nprint(\"Direct from data:\")\nprint(f\"2:1 - 1:1 = {gave_21 - gave_11:.4f}\")\nprint(f\"3:1 - 1:1 = {gave_31 - gave_11:.4f}\")\nprint(f\"3:1 - 2:1 = {gave_31 - gave_21:.4f}\")\n\nDirect from data:\n2:1 - 1:1 = 0.0019\n3:1 - 1:1 = 0.0020\n3:1 - 2:1 = 0.0001\n\n\n\n# from model\nb2 = model.params['ratio2']\nb3 = model.params['ratio3']\n\nprint(\"\\nFrom regression coefficients:\")\nprint(f\"2:1 - 1:1 = {b2:.4f}\")        # b2 就是 2:1 相對於 1:1 的差\nprint(f\"3:1 - 1:1 = {b3:.4f}\")        # b3 就是 3:1 相對於 1:1 的差\nprint(f\"3:1 - 2:1 = {b3 - b2:.4f}\")  # b3 相對於 1:1，再減去 b2\n\n\nFrom regression coefficients:\n2:1 - 1:1 = 0.0019\n3:1 - 1:1 = 0.0020\n3:1 - 2:1 = 0.0001\n\n\n\namount_t = data[data['treatment'] == 1]['amount'].dropna()\namount_c = data[data['treatment'] == 0]['amount'].dropna()\n\nt_stat, p_val = stats.ttest_ind(amount_t, amount_c, equal_var=False)\n\nprint(f\"T-statistic: {t_stat:.3f}\")\nprint(f\"P-value: {p_val:.4f}\")\nprint(f\"Mean difference: {amount_t.mean() - amount_c.mean():.3f}\")\n\nT-statistic: 1.918\nP-value: 0.0551\nMean difference: 0.154\n\n\n\ndf_positive = data[(data['amount'] &gt; 0) & data['treatment'].notnull()]\n\nX = sm.add_constant(df_positive['treatment'])\ny = df_positive['amount']\n\nmodel = sm.OLS(y, X).fit()\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.561\nTime:                        00:05:31   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\ndf_positive = data[(data['amount'] &gt; 0) & data['treatment'].notnull()]\n\n# 分成 treatment 和 control\namount_t = df_positive[df_positive['treatment'] == 1]['amount']\namount_c = df_positive[df_positive['treatment'] == 0]['amount']\n\n# 計算平均\nmean_t = amount_t.mean()\nmean_c = amount_c.mean()\n\n# 畫圖：Treatment group\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.hist(amount_t, bins=30, color='skyblue', edgecolor='black')\nplt.axvline(mean_t, color='red', linestyle='--', label=f'Mean = {mean_t:.2f}')\nplt.title('Donation Amounts: Treatment Group')\nplt.xlabel('Amount ($)')\nplt.ylabel('Frequency')\nplt.legend()\n\n# 畫圖：Control group\nplt.subplot(1, 2, 2)\nplt.hist(amount_c, bins=30, color='lightgray', edgecolor='black')\nplt.axvline(mean_c, color='red', linestyle='--', label=f'Mean = {mean_c:.2f}')\nplt.title('Donation Amounts: Control Group')\nplt.xlabel('Amount ($)')\nplt.ylabel('Frequency')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\ncontrol = data[(data['treatment'] == 0) & (data['amount'] &gt; 0)]['amount'].values\ntreatment = data[(data['treatment'] == 1) & (data['amount'] &gt; 0)]['amount'].values\n\n# Step 1: 抽樣模擬\nnp.random.seed(42)\ndraws_control = np.random.choice(control, 100000, replace=True)\ndraws_treatment = np.random.choice(treatment, 10000, replace=True)\n\n# Step 2: 算出 10,000 個差異值（對應 index）\ndifferences = draws_treatment - draws_control[:10000]\n\n# Step 3: 算累積平均\ncumulative_avg = np.cumsum(differences) / np.arange(1, len(differences) + 1)\n\n# Step 4: 畫圖\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, color='steelblue', label='Cumulative Average of Differences')\nplt.axhline(np.mean(treatment) - np.mean(control), color='red', linestyle='--', label='True Mean Difference')\nplt.title('Cumulative Average of Donation Differences (Treatment - Control)')\nplt.xlabel('Number of Simulated Pairs')\nplt.ylabel('Cumulative Average Difference ($)')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\ncontrol = data[(data['treatment'] == 0) & (data['amount'] &gt; 0)]['amount'].values\ntreatment = data[(data['treatment'] == 1) & (data['amount'] &gt; 0)]['amount'].values\n\n# 模擬參數\nsample_sizes = [50, 200, 500, 1000]\nn_simulations = 1000\n\n# 畫圖\nplt.figure(figsize=(18, 4))\n\nfor i, size in enumerate(sample_sizes):\n    diff_list = []\n    for _ in range(n_simulations):\n        draw_c = np.random.choice(control, size, replace=True)\n        draw_t = np.random.choice(treatment, size, replace=True)\n        diff = np.mean(draw_t) - np.mean(draw_c)\n        diff_list.append(diff)\n\n    # 畫圖\n    plt.subplot(1, 4, i+1)\n    plt.hist(diff_list, bins=30, color='skyblue', edgecolor='black')\n    plt.axvline(x=0, color='red', linestyle='--', label='Zero Line')\n    plt.title(f'Sample size = {size}')\n    plt.xlabel('Mean Difference ($)')\n    plt.ylabel('Frequency')\n    plt.legend()\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "hw1_questions.html#linear-regression-validation",
    "href": "hw1_questions.html#linear-regression-validation",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Linear Regression Validation",
    "text": "Linear Regression Validation\nTo confirm the t-test results, we also ran simple linear regressions for each variable using the treatment indicator as the independent variable. This allows us to check whether the coefficient on treatment (i.e., the mean difference between groups) matches the value from the t-test.\n\n\n🔁 Regression Model\nFor each variable (e.g., mrm2), we estimate the model: \\[\nY_i = \\beta_0 + \\beta_1 \\cdot \\text{treatment}_i + \\epsilon_i\n\\]\nWhere: - ( Y_i ) is the outcome variable (mrm2, freq, etc.) - ( _i = 1 ) if the observation is in the treatment group, 0 otherwise\n- ( _1 ) represents the difference in means between the treatment and control groups\n\n\n\n💡 Interpretation\n\nIf the coefficient of treatment is not statistically significant, it means there is no difference between the groups, which supports the randomization.\nThe p-value and 95% confidence interval should match the t-test results exactly.\nFor mrm2 &gt; ✅ The coefficient for treatment is 0.009, with a p-value of 0.940, which is exactly consistent with the t-test result. The 95% confidence interval also matches.\n\n\n\n\n💻 Regression Code\nimport statsmodels.api as sm\n\n# Prepare data\ndata = pd.read_stata(\"karlan_list_2007.dta\")\ndf_clean = data[['mrm2', 'treatment']].dropna()\n\n# Define X and y\nX = sm.add_constant(df_clean['treatment'])  # Adds intercept\ny = df_clean['mrm2']\n\n# Fit the model\nmodel = sm.OLS(y, X).fit()\n\n# Print regression result\nprint(model.summary())"
  },
  {
    "objectID": "blog/blog.html",
    "href": "blog/blog.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe study found that announcing a matching grant significantly increased both the likelihood of donation and the average amount given. However, increasing the match ratio—such as from 1:1 to 3:1—did not yield any additional gains in giving. Interestingly, the effectiveness of matching grants also varied by political geography: donors in Republican-leaning (“red”) states were more responsive than those in Democratic-leaning (“blue”) states. These results challenge conventional fundraising wisdom and offer practical insights for designing more effective donation campaigns.\nThis project aims to replicate their findings."
  },
  {
    "objectID": "blog/blog.html#introduction",
    "href": "blog/blog.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe study found that announcing a matching grant significantly increased both the likelihood of donation and the average amount given. However, increasing the match ratio—such as from 1:1 to 3:1—did not yield any additional gains in giving. Interestingly, the effectiveness of matching grants also varied by political geography: donors in Republican-leaning (“red”) states were more responsive than those in Democratic-leaning (“blue”) states. These results challenge conventional fundraising wisdom and offer practical insights for designing more effective donation campaigns.\nThis project aims to replicate their findings."
  },
  {
    "objectID": "blog/blog.html#data",
    "href": "blog/blog.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nData Description\nThis dataset originates from the field experiment conducted by Karlan and List (2007), in which 50,083 prior donors were sent fundraising letters randomly assigned to different treatments. Each row represents one individual who received a solicitation letter.\n\n\nDataset Overview\n\nTotal observations: 50,083\nUnit of observation: Individual donor\nDesign: Randomized field experiment with control and treatment groups\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\nKey Variables Summary\n\n\n\n\n\n\n\n\nVariable\nMean\nDescription\n\n\n\n\ntreatment\n0.667\nReceived a treatment letter (matching/challenge)\n\n\ncontrol\n0.333\nReceived a standard control letter\n\n\ngave\n0.021\nDonated (binary: 1 if donated, 0 otherwise)\n\n\namount\n0.916\nDonation amount (including 0s for non-donors)\n\n\namountchange\n-52.67\nChange in amount given compared to previous donations\n\n\nhpa\n59.38\nHighest previous contribution\n\n\nltmedmra\n0.494\nIndicator for small prior donors (last gift &lt; $35)\n\n\nyear5\n0.509\nDonor for at least 5 years\n\n\ndormant\n0.523\nAlready donated in 2005\n\n\nfemale\n0.278\nFemale donor\n\n\ncouple\n0.092\nCouple donor\n\n\n\n\n\nTreatment Group Assignment\n\n\n\nVariable\nMean\nDescription\n\n\n\n\nratio2\n0.222\nReceived 2:1 matching treatment\n\n\nratio3\n0.222\nReceived 3:1 matching treatment\n\n\nsize25\n0.167\n$25,000 match threshold\n\n\nsize50\n0.167\n$50,000 match threshold\n\n\nsize100\n0.167\n$100,000 match threshold\n\n\nsizeno\n0.167\nUnstated match threshold\n\n\naskd1\n0.222\nSuggested amount = last donation\n\n\naskd2\n0.222\nSuggested amount = 1.25x last donation\n\n\naskd3\n0.222\nSuggested amount = 1.5x last donation\n\n\n\n\n\nPolitical and Geographic Context\n\n\n\n\n\n\n\n\nVariable\nMean\nDescription\n\n\n\n\nred0\n0.404\nLives in a Republican-leaning (red) state\n\n\nblue0\n0.596\nLives in a Democratic-leaning (blue) state\n\n\nredcty\n0.510\nLives in a red county\n\n\nperbush\n0.489\nState-level vote share for Bush (2004)\n\n\n\n\n\nZip Code Demographics\n\n\n\n\n\n\n\n\nVariable\nMean\nDescription\n\n\n\n\npwhite\n0.820\nProportion of white residents\n\n\npblack\n0.087\nProportion of Black residents\n\n\npage18_39\n0.322\nProportion aged 18–39\n\n\nmedian_hhincome\n$54,816\nMedian household income\n\n\npowner\n0.669\nProportion of homeowners\n\n\npsch_atlstba\n0.392\nProportion with at least a bachelor’s degree\n\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\n\nT-test vs. Linear Regression\nTo verify whether the random assignment was successful, we tested a few non-outcome variables to see if treatment and control groups differ significantly at the 95% confidence level. This helps us confirm whether any observed treatment effects later can be attributed to the intervention itself, not to pre-existing group differences.\nWe tested four variables: - mrm2 (months since last donation) - freq (number of prior donations) - amountchange (change in donation amount) - female (gender)\n\n\n\nHypothesis\nFor each variable, we test:\n\nNull hypothesis (H₀): There is no difference in means between treatment and control groups.\nAlternative hypothesis (H₁): There is a difference in means between the groups.\n\n\n\n\nT-test Results\n\n\n\n\n\n\n\n\n\n\n\nFeature\nMean\nStd\nT-statistic\nP-value\n95% Confidence Interval\n\n\n\n\nmrm2\n13.007\n12.081\n0.119\n0.905\n(-0.211, 0.238)\n\n\nfreq\n8.039\n11.394\n-0.111\n0.912\n(-0.224, 0.200)\n\n\namountchange\n-52.672\n1267.239\n0.527\n0.598\n(-17.216, 29.877)\n\n\nfemale\n0.278\n0.448\n-1.758\n0.079\n(-0.016, 0.001)\n\n\n\n\nAll p-values are above 0.05, so we fail to reject the null hypothesis. There is no statistically significant difference between the treatment and control groups for any of these variables, indicating that random assignment was successful.\n\n\n\n\nT-test Code\n# For 'mrm2' as an example\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\n\ndata = pd.read_stata(\"karlan_list_2007.dta\")\ndf_treatment = data[data['treatment'] == 1]['mrm2'].dropna()\ndf_control = data[data['treatment'] == 0]['mrm2'].dropna()\n\nt_stat, p_val = stats.ttest_ind(df_treatment, df_control, equal_var=True)\n\nprint(f\"T-statistic: {t_stat:.3f}\")\nprint(f\"P-value: {p_val:.4f}\")\n\nmean_diff = df_treatment.mean() - df_control.mean()\nn1, n2 = len(df_treatment), len(df_control)\ns1, s2 = df_treatment.std(ddof=1), df_control.std(ddof=1)\n\nsp = np.sqrt(((n1 - 1)*s1**2 + (n2 - 1)*s2**2) / (n1 + n2 - 2))\nse = sp * np.sqrt(1/n1 + 1/n2)\n\nt_crit = stats.t.ppf(0.975, df=n1 + n2 - 2)\nci_low = mean_diff - t_crit * se\nci_high = mean_diff + t_crit * se\n\nprint(f\"\\nMean Difference: {mean_diff:.3f}\")\nprint(f\"95% Confidence Interval: ({ci_low:.3f}, {ci_high:.3f})\")\n\n\nLinear Regression Validation\nTo confirm the t-test results, we also ran simple linear regressions for each variable using the treatment indicator as the independent variable. This allows us to check whether the coefficient on treatment (i.e., the mean difference between groups) matches the value from the t-test.\n\n\n\nRegression Model\nFor each variable (e.g., mrm2), we estimate the model: \\[\nY_i = \\beta_0 + \\beta_1 \\cdot \\text{treatment}_i + \\epsilon_i\n\\]\nWhere:\n\n\\(Y_i\\) is the outcome variable (e.g., mrm2, freq, etc.)\n\\(\\text{treatment}_i = 1\\) if the observation is in the treatment group, and \\(0\\) otherwise\n\n\\(\\beta_1\\) represents the difference in means between the treatment and control groups\n\n\nIf the coefficient of treatment is not statistically significant, it means there is no difference between the groups, which supports the randomization.\nThe p-value and 95% confidence interval should match the t-test results exactly.\n\n\n\nRegression Code\nimport statsmodels.api as sm\n\n# Prepare data\ndata = pd.read_stata(\"karlan_list_2007.dta\")\ndf_clean = data[['mrm2', 'treatment']].dropna()\n\n# Define X and y\nX = sm.add_constant(df_clean['treatment'])  # Adds intercept\ny = df_clean['mrm2']\n\n# Fit the model\nmodel = sm.OLS(y, X).fit()\n\n# Print regression result\nprint(model.summary())\nFor mrm2: The coefficient for treatment is 0.009, with a p-value of 0.940, which is exactly consistent with the t-test result. The 95% confidence interval also matches.\nSo the treatment group and the control group prove to be randomly selected and have no group differences."
  },
  {
    "objectID": "blog/blog.html#experimental-results",
    "href": "blog/blog.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\nThe bar chart below shows the proportion of people who donated in each group.\n\n\n\nDonation Rate by Group\n\n\n\n\nImpact of Treatment on Donation Behavior\nWe tested whether individuals who received a treatment letter (with a matching grant offer) were more likely to make a charitable donation compared to those who received a standard control letter.\n\n\nT-test Code\ndf_treatment = data[data['treatment'] == 1]['gave'].dropna()\ndf_control = data[data['treatment'] == 0]['gave'].dropna()\n\nt_stat, p_val = stats.ttest_ind(df_treatment, df_control, equal_var=True)\n\nprint(f\"T-statistic: {t_stat:.3f}\")\nprint(f\"P-value: {p_val:.4f}\")\n\nmean_diff = df_treatment.mean() - df_control.mean()\nn1, n2 = len(df_treatment), len(df_control)\ns1, s2 = df_treatment.std(ddof=1), df_control.std(ddof=1)\n\nsp = np.sqrt(((n1 - 1)*s1**2 + (n2 - 1)*s2**2) / (n1 + n2 - 2))\nse = sp * np.sqrt(1/n1 + 1/n2)\n\nt_crit = stats.t.ppf(0.975, df=n1 + n2 - 2)\nci_low = mean_diff - t_crit * se\nci_high = mean_diff + t_crit * se\n\nprint(f\"\\nMean Difference: {mean_diff:.3f}\")\nprint(f\"95% Confidence Interval: ({ci_low:.3f}, {ci_high:.3f})\")\nA t-test comparing the proportion of donors between the two groups revealed a statistically significant difference: individuals in the treatment group were more likely to donate. The mean difference in donation rates was 0.004, with a t-statistic of 3.101 and a p-value of 0.0019. The 95% confidence interval for the difference was (0.002, 0.007), which does not include zero — providing strong evidence that the treatment had a real effect.\nTo confirm this result, we ran a bivariate linear regression where the outcome variable was a binary indicator of whether a donation was made.\n\n\nRegression Code\ndf_clean = data[['gave', 'treatment']].dropna()\nX = sm.add_constant(df_clean['treatment']) \ny = df_clean['gave']\nmodel = sm.OLS(y, X).fit()\n\nprint(model.summary())\nThe coefficient on the treatment variable was 0.0042, with a p-value of 0.002, and the 95% confidence interval was also (0.002, 0.007). This perfectly aligns with the t-test results and confirms that the treatment increased the likelihood of giving.\nThis result supports the idea that including a matching grant offer in a donation appeal can meaningfully influence behavior. Even though the financial amount offered as a match was the same, simply presenting the opportunity to have one’s donation matched significantly increased the chance that someone would donate at all.\nIn behavioral terms, this suggests that people respond to cues of increased impact — like knowing their donation will be matched. It may enhance the perceived effectiveness or social validation of their gift. This finding highlights how small changes in how we ask for donations can significantly affect participation rates.\n\n\nProbit Regression Analysis\nTo better understand the impact of the treatment on donation behavior, we estimated a probit regression where the binary outcome variable was whether or not a donation was made (gave), and the explanatory variable was the assignment to the treatment group.\n\n\nCode\ndf_clean = data[['gave', 'treatment']].dropna()\n\nX = sm.add_constant(df_clean['treatment'])\ny = df_clean['gave']\n\nprobit_model = sm.Probit(y, X).fit()\nprint(probit_model.summary())\nThe estimated coefficient on the treatment variable is 0.0868, with a z-statistic of 3.113 and a p-value of 0.002, indicating that the effect is statistically significant at the 1% level. The 95% confidence interval for the coefficient is (0.032, 0.141), which excludes zero.\nThis result replicates Table 3, Column 1 of Karlan & List (2007), confirming that individuals in the treatment group were significantly more likely to make a charitable donation than those in the control group.\nThe positive and significant coefficient on treatment suggests that receiving a fundraising letter with a matching grant offer makes people more likely to donate, even after controlling for random assignment through a nonlinear probability model.\nIn simpler terms, this shows that human behavior is sensitive to perceived impact. When people are told that their donation will be matched by someone else, they are more motivated to act. This finding reinforces the behavioral insight that the way a request is framed — even without changing the actual cost — can meaningfully affect decision-making.\nThis has real-world implications for how nonprofits design their appeals: adding a matching offer not only increases donation amounts, but also boosts the likelihood that people will give at all.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\nWe test whether higher match ratios (2:1, 3:1) increase the probability of donation compared to a baseline 1:1 match. The following T-tests compare donation rates between these match conditions.\n\n\nT-test Code\n\n# Filter for treatment group with valid ratio and donation outcome\ndf_ratio = data[(data['treatment'] == 1) & (data['ratio'].notnull()) & (data['gave'].notnull())]\n\n# Split by match ratio\ngave_11 = df_ratio[df_ratio['ratio'] == 1]['gave'].dropna()\ngave_21 = df_ratio[df_ratio['ratio'] == 2]['gave'].dropna()\ngave_31 = df_ratio[df_ratio['ratio'] == 3]['gave'].dropna()\n\n# Donation rates\nmean_11 = gave_11.mean()\nmean_21 = gave_21.mean()\nmean_31 = gave_31.mean()\n\nprint(\"Donation Rates:\")\nprint(f\"1:1  = {mean_11:.4f}\")\nprint(f\"2:1  = {mean_21:.4f}\")\nprint(f\"3:1  = {mean_31:.4f}\")\n\n# T-tests\nprint(\"\\nT-test Results:\")\nt_21, p_21 = stats.ttest_ind(gave_21, gave_11, equal_var=False)\nt_31, p_31 = stats.ttest_ind(gave_31, gave_11, equal_var=False)\nt_32, p_32 = stats.ttest_ind(gave_31, gave_21, equal_var=False)\n\nprint(f\"2:1 vs 1:1 → T = {t_21:.3f}, p = {p_21:.4f}\")\nprint(f\"3:1 vs 1:1 → T = {t_31:.3f}, p = {p_31:.4f}\")\nprint(f\"3:1 vs 2:1 → T = {t_32:.3f}, p = {p_32:.4f}\")\n\nT-test Results:\n\n2:1 vs 1:1 → T = 0.965, p = 0.3345\n3:1 vs 1:1 → T = 1.015, p = 0.3101\n3:1 vs 2:1 → T = 0.050, p = 0.9600\n\n\nAlthough the donation rates appear slightly higher for the 2:1 and 3:1 match offers (2.26% and 2.27%) compared to the 1:1 match (2.07%), the differences are not statistically significant. All p-values are far above the 0.05 threshold, meaning we cannot reject the null hypothesis of equal donation probabilities between match ratio groups.\nWe now assess the effect of different match ratios on donation behavior using a linear regression model. We create dummy variables for 2:1 and 3:1 match ratios, using 1:1 as the reference group.\n\n\nRegression Code\n\n# Filter treatment group and prepare ratio dummies\ndf_ratio = data[(data['treatment'] == 1) & (data['ratio'].isin([1,2,3])) & (data['gave'].notnull())]\ndf_ratio['ratio2'] = (df_ratio['ratio'] == 2).astype(int)\ndf_ratio['ratio3'] = (df_ratio['ratio'] == 3).astype(int)\n\n# Run regression\nX = sm.add_constant(df_ratio[['ratio2', 'ratio3']])\ny = df_ratio['gave']\nmodel = sm.OLS(y, X).fit()\nprint(model.summary())\n\nRegression Results Summary:\n\nIntercept (baseline 1:1 match): 0.0207\nCoefficient for 2:1 match: +0.0019, p = 0.338\nCoefficient for 3:1 match: +0.0020, p = 0.313\n\n\nThis regression confirms the earlier t-test findings: although donation rates appear slightly higher for 2:1 and 3:1 match ratios compared to 1:1, the differences are not statistically significant. Both p-values are above 0.3, and the confidence intervals include zero, suggesting no meaningful increase in donation probability from increasing the match ratio.\nThis matches the earlier t-test results and supports the paper’s finding.\nWe also compare donation rates across match ratios in two ways:\n\nDirectly from the data — by calculating group means\n\nFrom the regression model — by examining the estimated coefficients\n\nBoth approaches provide estimates of how 2:1 and 3:1 match ratios compare to the 1:1 baseline.\n\n\nCode\n# Directly from data\ngave_11 = df_ratio[df_ratio['ratio'] == 1]['gave'].mean()\ngave_21 = df_ratio[df_ratio['ratio'] == 2]['gave'].mean()\ngave_31 = df_ratio[df_ratio['ratio'] == 3]['gave'].mean()\n\nprint(\"Direct from data:\")\nprint(f\"2:1 - 1:1 = {gave_21 - gave_11:.4f}\")\nprint(f\"3:1 - 1:1 = {gave_31 - gave_11:.4f}\")\nprint(f\"3:1 - 2:1 = {gave_31 - gave_21:.4f}\")\n\n# From regression coefficients\nb2 = model.params['ratio2']\nb3 = model.params['ratio3']\n\nprint(\"\\nFrom regression coefficients:\")\nprint(f\"2:1 - 1:1 = {b2:.4f}\")\nprint(f\"3:1 - 1:1 = {b3:.4f}\")\nprint(f\"3:1 - 2:1 = {b3 - b2:.4f}\")\n\nDirect from data: Response rate difference (2:1 - 1:1): 0.0019\nDirect from data: Response rate difference (3:1 - 1:1): 0.0020\nDirect from data: Response rate difference (3:1 - 2:1): 0.0001\nFrom regression: Response rate difference (2:1 - 1:1): 0.0019\nFrom regression: Response rate difference (3:1 - 1:1): 0.0020\nFrom regression: Response rate difference (3:1 - 2:1): 0.0001\n\nThese results are consistent whether calculated directly from the raw data or from the estimated regression coefficients.\nSuch small differences, combined with the non-significant p-values seen earlier, indicate that increasing the match ratio does not lead to a meaningful increase in the likelihood of donation.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\nIn addition to increasing the likelihood of giving, does the treatment also lead to larger donation amounts among donors?\nWe conduct a t-test comparing the donation amounts (amount) between the treatment and control groups.\n\n\nT-test Code\n# T-test comparing donation amounts\namount_t = data[data['treatment'] == 1]['amount'].dropna()\namount_c = data[data['treatment'] == 0]['amount'].dropna()\n\nfrom scipy import stats\nt_stat, p_val = stats.ttest_ind(amount_t, amount_c, equal_var=False)\n\nprint(f\"T-statistic: {t_stat:.3f}\")\nprint(f\"P-value: {p_val:.4f}\")\nprint(f\"Mean difference: {amount_t.mean() - amount_c.mean():.3f}\")\n\nResults\n\nT-statistic: 1.918\nP-value: 0.0551\nMean difference: $0.154\n\n\nWhile the treatment group donated an average of $0.154 more than the control group, the difference is not statistically significant at the 5% level. The p-value of 0.0551 is just above the standard cutoff of 0.05.\nThis suggests a potential positive effect of treatment on donation amount, but the evidence is not strong enough to make a definitive conclusion.\nNow we restrict the sample to only those individuals who made a donation (amount &gt; 0) and examine whether assignment to the treatment group influenced the amount donated, conditional on giving.\nThis analysis estimates the conditional average treatment effect (CATE) on donation size.\n\n\nRegression Code\n# Filter: only donors\ndf_positive = data[(data['amount'] &gt; 0) & data['treatment'].notnull()]\n\n# Run regression\nX = sm.add_constant(df_positive['treatment'])\ny = df_positive['amount']\nmodel = sm.OLS(y, X).fit()\n\nprint(model.summary())\n\nResults\n\nIntercept (control group mean donation): $45.54\nTreatment coefficient: -1.668, p = 0.561\n\n\nAmong those who donated, individuals in the treatment group gave $1.67 less on average than those in the control group. However, this difference is not statistically significant (p = 0.561), and the confidence interval includes both negative and positive values (-7.31 to +3.97). This means that while the direction of the estimate is slightly negative, we have no evidence to conclude that the treatment caused people to give more or less, once they had already decided to donate.\nSo we do two bar chart to show the distribution directly. The histograms below display the distribution of donation amounts among individuals who made a donation, separately for the treatment and control groups. Each plot includes a red dashed line indicating the sample mean.\n\n\n\nDonation Amounts\n\n\nFrom the plots, we observe that:\n\nBoth groups are highly right-skewed: most donors give between $10–$50, but a small number give substantially more (some over $200).\nThe control group has a slightly higher mean donation ($45.54) compared to the treatment group ($43.87).\nThe two distributions are fairly similar in shape, with the treatment group having a marginally heavier tail but not substantially so.\n\nThis observation is consistent with our previous regression analysis (run on donors only), where the treatment group donated $1.67 less on average, but the difference was not statistically significant (p = 0.561).\nWhile the treatment had a positive effect on donation likelihood, it did not lead to higher donation amounts among those who chose to give. In fact, the treatment group donated slightly less on average.\nThis reinforces the interpretation that the matching grant offer may influence whether someone donates, but does not significantly affect how much they donate, once they decide to give.\n\n\nSimulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\n\nLaw of Large Numbers\nNext we want to simulate the cumulative average of differences in donation amounts between treatment and control groups.\nThis helps us visualize how a sample average stabilizes as the number of samples increases.\n\n\n\nCumulative Average of Donation Differences\n\n\n\n\n\nSimulation Code\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Filter for positive donations\ncontrol = data[(data['treatment'] == 0) & (data['amount'] &gt; 0)]['amount'].values\ntreatment = data[(data['treatment'] == 1) & (data['amount'] &gt; 0)]['amount'].values\n\n# Simulate draws\nnp.random.seed(42)\ndraws_control = np.random.choice(control, 100000, replace=True)\ndraws_treatment = np.random.choice(treatment, 10000, replace=True)\n\n# Calculate differences\ndifferences = draws_treatment - draws_control[:10000]\n\n# Compute cumulative average\ncumulative_avg = np.cumsum(differences) / np.arange(1, len(differences) + 1)\n\n# Plot\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, label='Cumulative Average of Differences', color='steelblue')\nplt.axhline(np.mean(treatment) - np.mean(control), color='red', linestyle='--', label='True Mean Difference')\nplt.title('Cumulative Average of Donation Differences (Treatment - Control)')\nplt.xlabel('Number of Simulated Pairs')\nplt.ylabel('Cumulative Average Difference ($)')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\nThis simulation illustrates how sample averages behave as we increase the number of observations. Initially, the cumulative average of differences is highly unstable, with large fluctuations. But as more pairs are sampled, the line converges toward the true mean difference, indicated by the red dashed line.\nThis is a direct demonstration of the Law of Large Numbers: as the number of samples increases, the sample mean gets closer to the population mean.\nIn this case, the simulation confirms that although there is considerable variation with small samples, the overall average difference in donations between the treatment and control groups stabilizes close to the true effect — which in our case is slightly negative.\n\n\nCentral Limit Theorem\nTo understand how sample size affects the precision and stability of estimated treatment effects, we simulate four sets of experiments with different sample sizes.\nFor each sample size (50, 200, 500, 1000), we:\n\nDraw n random samples from both the treatment and control distributions\nCompute the average donation difference (treatment - control)\nRepeat this process 1000 times\nPlot the distribution (histogram) of the 1000 average differences\n\n\n\n\nDifferent Sample Size Simulation\n\n\n\n\nSimulation Code\n\n# Filter: only positive donation amounts\ncontrol = data[(data['treatment'] == 0) & (data['amount'] &gt; 0)]['amount'].values\ntreatment = data[(data['treatment'] == 1) & (data['amount'] &gt; 0)]['amount'].values\n\nsample_sizes = [50, 200, 500, 1000]\nn_simulations = 1000\n\nplt.figure(figsize=(20, 4))\nfor i, size in enumerate(sample_sizes):\n    diffs = []\n    for _ in range(n_simulations):\n        c = np.random.choice(control, size, replace=True)\n        t = np.random.choice(treatment, size, replace=True)\n        diffs.append(np.mean(t) - np.mean(c))\n\n    plt.subplot(1, 4, i + 1)\n    plt.hist(diffs, bins=30, color='skyblue', edgecolor='black')\n    plt.axvline(x=0, color='red', linestyle='--', label='Zero Line')\n    plt.title(f'Sample size = {size}')\n    plt.xlabel('Mean Difference ($)')\n    plt.ylabel('Frequency')\n    plt.legend()\n\nplt.tight_layout()\nplt.show()\nAs sample size increases: - The distribution of estimated treatment effects becomes narrower and more concentrated - At small sample sizes (like 50), the distribution is wide, and zero is near the center, indicating a high degree of uncertainty - At larger sample sizes (like 1000), the distribution is tighter, and zero lies closer to the edge of the distribution, suggesting a more stable and possibly significant treatment effect\nThis simulation highlights how larger sample sizes reduce variance and help us better detect true effects.\nLarger samples lead to more precise and stable estimates of the treatment effect"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe study found that announcing a matching grant significantly increased both the likelihood of donation and the average amount given. However, increasing the match ratio—such as from 1:1 to 3:1—did not yield any additional gains in giving. Interestingly, the effectiveness of matching grants also varied by political geography: donors in Republican-leaning (“red”) states were more responsive than those in Democratic-leaning (“blue”) states. These results challenge conventional fundraising wisdom and offer practical insights for designing more effective donation campaigns.\nThis project aims to replicate their findings."
  },
  {
    "objectID": "blog.html#introduction",
    "href": "blog.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe study found that announcing a matching grant significantly increased both the likelihood of donation and the average amount given. However, increasing the match ratio—such as from 1:1 to 3:1—did not yield any additional gains in giving. Interestingly, the effectiveness of matching grants also varied by political geography: donors in Republican-leaning (“red”) states were more responsive than those in Democratic-leaning (“blue”) states. These results challenge conventional fundraising wisdom and offer practical insights for designing more effective donation campaigns.\nThis project aims to replicate their findings."
  },
  {
    "objectID": "blog.html#data",
    "href": "blog.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nData Description\nThis dataset originates from the field experiment conducted by Karlan and List (2007), in which 50,083 prior donors were sent fundraising letters randomly assigned to different treatments. Each row represents one individual who received a solicitation letter.\n\n\nDataset Overview\n\nTotal observations: 50,083\nUnit of observation: Individual donor\nDesign: Randomized field experiment with control and treatment groups\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\nKey Variables Summary\n\n\n\n\n\n\n\n\nVariable\nMean\nDescription\n\n\n\n\ntreatment\n0.667\nReceived a treatment letter (matching/challenge)\n\n\ncontrol\n0.333\nReceived a standard control letter\n\n\ngave\n0.021\nDonated (binary: 1 if donated, 0 otherwise)\n\n\namount\n0.916\nDonation amount (including 0s for non-donors)\n\n\namountchange\n-52.67\nChange in amount given compared to previous donations\n\n\nhpa\n59.38\nHighest previous contribution\n\n\nltmedmra\n0.494\nIndicator for small prior donors (last gift &lt; $35)\n\n\nyear5\n0.509\nDonor for at least 5 years\n\n\ndormant\n0.523\nAlready donated in 2005\n\n\nfemale\n0.278\nFemale donor\n\n\ncouple\n0.092\nCouple donor\n\n\n\n\n\nTreatment Group Assignment\n\n\n\nVariable\nMean\nDescription\n\n\n\n\nratio2\n0.222\nReceived 2:1 matching treatment\n\n\nratio3\n0.222\nReceived 3:1 matching treatment\n\n\nsize25\n0.167\n$25,000 match threshold\n\n\nsize50\n0.167\n$50,000 match threshold\n\n\nsize100\n0.167\n$100,000 match threshold\n\n\nsizeno\n0.167\nUnstated match threshold\n\n\naskd1\n0.222\nSuggested amount = last donation\n\n\naskd2\n0.222\nSuggested amount = 1.25x last donation\n\n\naskd3\n0.222\nSuggested amount = 1.5x last donation\n\n\n\n\n\nPolitical and Geographic Context\n\n\n\n\n\n\n\n\nVariable\nMean\nDescription\n\n\n\n\nred0\n0.404\nLives in a Republican-leaning (red) state\n\n\nblue0\n0.596\nLives in a Democratic-leaning (blue) state\n\n\nredcty\n0.510\nLives in a red county\n\n\nperbush\n0.489\nState-level vote share for Bush (2004)\n\n\n\n\n\nZip Code Demographics\n\n\n\n\n\n\n\n\nVariable\nMean\nDescription\n\n\n\n\npwhite\n0.820\nProportion of white residents\n\n\npblack\n0.087\nProportion of Black residents\n\n\npage18_39\n0.322\nProportion aged 18–39\n\n\nmedian_hhincome\n$54,816\nMedian household income\n\n\npowner\n0.669\nProportion of homeowners\n\n\npsch_atlstba\n0.392\nProportion with at least a bachelor’s degree\n\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\n\nT-test vs. Linear Regression\nTo verify whether the random assignment was successful, we tested a few non-outcome variables to see if treatment and control groups differ significantly at the 95% confidence level. This helps us confirm whether any observed treatment effects later can be attributed to the intervention itself, not to pre-existing group differences.\nWe tested four variables: - mrm2 (months since last donation) - freq (number of prior donations) - amountchange (change in donation amount) - female (gender)\n\n\n\nHypothesis\nFor each variable, we test:\n\nNull hypothesis (H₀): There is no difference in means between treatment and control groups.\nAlternative hypothesis (H₁): There is a difference in means between the groups.\n\n\n\n\nT-test Results\n\n\n\n\n\n\n\n\n\n\n\nFeature\nMean\nStd\nT-statistic\nP-value\n95% Confidence Interval\n\n\n\n\nmrm2\n13.007\n12.081\n0.119\n0.905\n(-0.211, 0.238)\n\n\nfreq\n8.039\n11.394\n-0.111\n0.912\n(-0.224, 0.200)\n\n\namountchange\n-52.672\n1267.239\n0.527\n0.598\n(-17.216, 29.877)\n\n\nfemale\n0.278\n0.448\n-1.758\n0.079\n(-0.016, 0.001)\n\n\n\n\nAll p-values are above 0.05, so we fail to reject the null hypothesis. There is no statistically significant difference between the treatment and control groups for any of these variables, indicating that random assignment was successful.\n\n\n\n\nT-test Code\n# For 'mrm2' as an example\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\n\ndata = pd.read_stata(\"karlan_list_2007.dta\")\ndf_treatment = data[data['treatment'] == 1]['mrm2'].dropna()\ndf_control = data[data['treatment'] == 0]['mrm2'].dropna()\n\nt_stat, p_val = stats.ttest_ind(df_treatment, df_control, equal_var=True)\n\nprint(f\"T-statistic: {t_stat:.3f}\")\nprint(f\"P-value: {p_val:.4f}\")\n\nmean_diff = df_treatment.mean() - df_control.mean()\nn1, n2 = len(df_treatment), len(df_control)\ns1, s2 = df_treatment.std(ddof=1), df_control.std(ddof=1)\n\nsp = np.sqrt(((n1 - 1)*s1**2 + (n2 - 1)*s2**2) / (n1 + n2 - 2))\nse = sp * np.sqrt(1/n1 + 1/n2)\n\nt_crit = stats.t.ppf(0.975, df=n1 + n2 - 2)\nci_low = mean_diff - t_crit * se\nci_high = mean_diff + t_crit * se\n\nprint(f\"\\nMean Difference: {mean_diff:.3f}\")\nprint(f\"95% Confidence Interval: ({ci_low:.3f}, {ci_high:.3f})\")\n\n\nLinear Regression Validation\nTo confirm the t-test results, we also ran simple linear regressions for each variable using the treatment indicator as the independent variable. This allows us to check whether the coefficient on treatment (i.e., the mean difference between groups) matches the value from the t-test.\n\n\n\nRegression Model\nFor each variable (e.g., mrm2), we estimate the model: \\[\nY_i = \\beta_0 + \\beta_1 \\cdot \\text{treatment}_i + \\epsilon_i\n\\]\nWhere:\n\n\\(Y_i\\) is the outcome variable (e.g., mrm2, freq, etc.)\n\\(\\text{treatment}_i = 1\\) if the observation is in the treatment group, and \\(0\\) otherwise\n\n\\(\\beta_1\\) represents the difference in means between the treatment and control groups\n\n\nIf the coefficient of treatment is not statistically significant, it means there is no difference between the groups, which supports the randomization.\nThe p-value and 95% confidence interval should match the t-test results exactly.\n\n\n\nRegression Code\nimport statsmodels.api as sm\n\n# Prepare data\ndata = pd.read_stata(\"karlan_list_2007.dta\")\ndf_clean = data[['mrm2', 'treatment']].dropna()\n\n# Define X and y\nX = sm.add_constant(df_clean['treatment'])  # Adds intercept\ny = df_clean['mrm2']\n\n# Fit the model\nmodel = sm.OLS(y, X).fit()\n\n# Print regression result\nprint(model.summary())\nFor mrm2: The coefficient for treatment is 0.009, with a p-value of 0.940, which is exactly consistent with the t-test result. The 95% confidence interval also matches.\nSo the treatment group and the control group prove to be randomly selected and have no group differences."
  },
  {
    "objectID": "blog.html#experimental-results",
    "href": "blog.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\nThe bar chart below shows the proportion of people who donated in each group.\n\n\n\nDonation Rate by Group\n\n\n\n\nImpact of Treatment on Donation Behavior\nWe tested whether individuals who received a treatment letter (with a matching grant offer) were more likely to make a charitable donation compared to those who received a standard control letter.\n\n\nT-test Code\ndf_treatment = data[data['treatment'] == 1]['gave'].dropna()\ndf_control = data[data['treatment'] == 0]['gave'].dropna()\n\nt_stat, p_val = stats.ttest_ind(df_treatment, df_control, equal_var=True)\n\nprint(f\"T-statistic: {t_stat:.3f}\")\nprint(f\"P-value: {p_val:.4f}\")\n\nmean_diff = df_treatment.mean() - df_control.mean()\nn1, n2 = len(df_treatment), len(df_control)\ns1, s2 = df_treatment.std(ddof=1), df_control.std(ddof=1)\n\nsp = np.sqrt(((n1 - 1)*s1**2 + (n2 - 1)*s2**2) / (n1 + n2 - 2))\nse = sp * np.sqrt(1/n1 + 1/n2)\n\nt_crit = stats.t.ppf(0.975, df=n1 + n2 - 2)\nci_low = mean_diff - t_crit * se\nci_high = mean_diff + t_crit * se\n\nprint(f\"\\nMean Difference: {mean_diff:.3f}\")\nprint(f\"95% Confidence Interval: ({ci_low:.3f}, {ci_high:.3f})\")\nA t-test comparing the proportion of donors between the two groups revealed a statistically significant difference: individuals in the treatment group were more likely to donate. The mean difference in donation rates was 0.004, with a t-statistic of 3.101 and a p-value of 0.0019. The 95% confidence interval for the difference was (0.002, 0.007), which does not include zero — providing strong evidence that the treatment had a real effect.\nTo confirm this result, we ran a bivariate linear regression where the outcome variable was a binary indicator of whether a donation was made.\n\n\nRegression Code\ndf_clean = data[['gave', 'treatment']].dropna()\nX = sm.add_constant(df_clean['treatment']) \ny = df_clean['gave']\nmodel = sm.OLS(y, X).fit()\n\nprint(model.summary())\nThe coefficient on the treatment variable was 0.0042, with a p-value of 0.002, and the 95% confidence interval was also (0.002, 0.007). This perfectly aligns with the t-test results and confirms that the treatment increased the likelihood of giving.\nThis result supports the idea that including a matching grant offer in a donation appeal can meaningfully influence behavior. Even though the financial amount offered as a match was the same, simply presenting the opportunity to have one’s donation matched significantly increased the chance that someone would donate at all.\nIn behavioral terms, this suggests that people respond to cues of increased impact — like knowing their donation will be matched. It may enhance the perceived effectiveness or social validation of their gift. This finding highlights how small changes in how we ask for donations can significantly affect participation rates.\n\n\nProbit Regression Analysis\nTo better understand the impact of the treatment on donation behavior, we estimated a probit regression where the binary outcome variable was whether or not a donation was made (gave), and the explanatory variable was the assignment to the treatment group.\n\n\nCode\ndf_clean = data[['gave', 'treatment']].dropna()\n\nX = sm.add_constant(df_clean['treatment'])\ny = df_clean['gave']\n\nprobit_model = sm.Probit(y, X).fit()\nprint(probit_model.summary())\nThe estimated coefficient on the treatment variable is 0.0868, with a z-statistic of 3.113 and a p-value of 0.002, indicating that the effect is statistically significant at the 1% level. The 95% confidence interval for the coefficient is (0.032, 0.141), which excludes zero.\nThis result replicates Table 3, Column 1 of Karlan & List (2007), confirming that individuals in the treatment group were significantly more likely to make a charitable donation than those in the control group.\nThe positive and significant coefficient on treatment suggests that receiving a fundraising letter with a matching grant offer makes people more likely to donate, even after controlling for random assignment through a nonlinear probability model.\nIn simpler terms, this shows that human behavior is sensitive to perceived impact. When people are told that their donation will be matched by someone else, they are more motivated to act. This finding reinforces the behavioral insight that the way a request is framed — even without changing the actual cost — can meaningfully affect decision-making.\nThis has real-world implications for how nonprofits design their appeals: adding a matching offer not only increases donation amounts, but also boosts the likelihood that people will give at all.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\nWe test whether higher match ratios (2:1, 3:1) increase the probability of donation compared to a baseline 1:1 match. The following T-tests compare donation rates between these match conditions.\n\n\nT-test Code\n\n# Filter for treatment group with valid ratio and donation outcome\ndf_ratio = data[(data['treatment'] == 1) & (data['ratio'].notnull()) & (data['gave'].notnull())]\n\n# Split by match ratio\ngave_11 = df_ratio[df_ratio['ratio'] == 1]['gave'].dropna()\ngave_21 = df_ratio[df_ratio['ratio'] == 2]['gave'].dropna()\ngave_31 = df_ratio[df_ratio['ratio'] == 3]['gave'].dropna()\n\n# Donation rates\nmean_11 = gave_11.mean()\nmean_21 = gave_21.mean()\nmean_31 = gave_31.mean()\n\nprint(\"Donation Rates:\")\nprint(f\"1:1  = {mean_11:.4f}\")\nprint(f\"2:1  = {mean_21:.4f}\")\nprint(f\"3:1  = {mean_31:.4f}\")\n\n# T-tests\nprint(\"\\nT-test Results:\")\nt_21, p_21 = stats.ttest_ind(gave_21, gave_11, equal_var=False)\nt_31, p_31 = stats.ttest_ind(gave_31, gave_11, equal_var=False)\nt_32, p_32 = stats.ttest_ind(gave_31, gave_21, equal_var=False)\n\nprint(f\"2:1 vs 1:1 → T = {t_21:.3f}, p = {p_21:.4f}\")\nprint(f\"3:1 vs 1:1 → T = {t_31:.3f}, p = {p_31:.4f}\")\nprint(f\"3:1 vs 2:1 → T = {t_32:.3f}, p = {p_32:.4f}\")\n\nT-test Results:\n\n2:1 vs 1:1 → T = 0.965, p = 0.3345\n3:1 vs 1:1 → T = 1.015, p = 0.3101\n3:1 vs 2:1 → T = 0.050, p = 0.9600\n\n\nAlthough the donation rates appear slightly higher for the 2:1 and 3:1 match offers (2.26% and 2.27%) compared to the 1:1 match (2.07%), the differences are not statistically significant. All p-values are far above the 0.05 threshold, meaning we cannot reject the null hypothesis of equal donation probabilities between match ratio groups.\nWe now assess the effect of different match ratios on donation behavior using a linear regression model. We create dummy variables for 2:1 and 3:1 match ratios, using 1:1 as the reference group.\n\n\nRegression Code\n\n# Filter treatment group and prepare ratio dummies\ndf_ratio = data[(data['treatment'] == 1) & (data['ratio'].isin([1,2,3])) & (data['gave'].notnull())]\ndf_ratio['ratio2'] = (df_ratio['ratio'] == 2).astype(int)\ndf_ratio['ratio3'] = (df_ratio['ratio'] == 3).astype(int)\n\n# Run regression\nX = sm.add_constant(df_ratio[['ratio2', 'ratio3']])\ny = df_ratio['gave']\nmodel = sm.OLS(y, X).fit()\nprint(model.summary())\n\nRegression Results Summary:\n\nIntercept (baseline 1:1 match): 0.0207\nCoefficient for 2:1 match: +0.0019, p = 0.338\nCoefficient for 3:1 match: +0.0020, p = 0.313\n\n\nThis regression confirms the earlier t-test findings: although donation rates appear slightly higher for 2:1 and 3:1 match ratios compared to 1:1, the differences are not statistically significant. Both p-values are above 0.3, and the confidence intervals include zero, suggesting no meaningful increase in donation probability from increasing the match ratio.\nThis matches the earlier t-test results and supports the paper’s finding.\nWe also compare donation rates across match ratios in two ways:\n\nDirectly from the data — by calculating group means\n\nFrom the regression model — by examining the estimated coefficients\n\nBoth approaches provide estimates of how 2:1 and 3:1 match ratios compare to the 1:1 baseline.\n\n\nCode\n# Directly from data\ngave_11 = df_ratio[df_ratio['ratio'] == 1]['gave'].mean()\ngave_21 = df_ratio[df_ratio['ratio'] == 2]['gave'].mean()\ngave_31 = df_ratio[df_ratio['ratio'] == 3]['gave'].mean()\n\nprint(\"Direct from data:\")\nprint(f\"2:1 - 1:1 = {gave_21 - gave_11:.4f}\")\nprint(f\"3:1 - 1:1 = {gave_31 - gave_11:.4f}\")\nprint(f\"3:1 - 2:1 = {gave_31 - gave_21:.4f}\")\n\n# From regression coefficients\nb2 = model.params['ratio2']\nb3 = model.params['ratio3']\n\nprint(\"\\nFrom regression coefficients:\")\nprint(f\"2:1 - 1:1 = {b2:.4f}\")\nprint(f\"3:1 - 1:1 = {b3:.4f}\")\nprint(f\"3:1 - 2:1 = {b3 - b2:.4f}\")\n\nDirect from data: Response rate difference (2:1 - 1:1): 0.0019\nDirect from data: Response rate difference (3:1 - 1:1): 0.0020\nDirect from data: Response rate difference (3:1 - 2:1): 0.0001\nFrom regression: Response rate difference (2:1 - 1:1): 0.0019\nFrom regression: Response rate difference (3:1 - 1:1): 0.0020\nFrom regression: Response rate difference (3:1 - 2:1): 0.0001\n\nThese results are consistent whether calculated directly from the raw data or from the estimated regression coefficients.\nSuch small differences, combined with the non-significant p-values seen earlier, indicate that increasing the match ratio does not lead to a meaningful increase in the likelihood of donation.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\nIn addition to increasing the likelihood of giving, does the treatment also lead to larger donation amounts among donors?\nWe conduct a t-test comparing the donation amounts (amount) between the treatment and control groups.\n\n\nT-test Code\n# T-test comparing donation amounts\namount_t = data[data['treatment'] == 1]['amount'].dropna()\namount_c = data[data['treatment'] == 0]['amount'].dropna()\n\nfrom scipy import stats\nt_stat, p_val = stats.ttest_ind(amount_t, amount_c, equal_var=False)\n\nprint(f\"T-statistic: {t_stat:.3f}\")\nprint(f\"P-value: {p_val:.4f}\")\nprint(f\"Mean difference: {amount_t.mean() - amount_c.mean():.3f}\")\n\nResults\n\nT-statistic: 1.918\nP-value: 0.0551\nMean difference: $0.154\n\n\nWhile the treatment group donated an average of $0.154 more than the control group, the difference is not statistically significant at the 5% level. The p-value of 0.0551 is just above the standard cutoff of 0.05.\nThis suggests a potential positive effect of treatment on donation amount, but the evidence is not strong enough to make a definitive conclusion.\nNow we restrict the sample to only those individuals who made a donation (amount &gt; 0) and examine whether assignment to the treatment group influenced the amount donated, conditional on giving.\nThis analysis estimates the conditional average treatment effect (CATE) on donation size.\n\n\nRegression Code\n# Filter: only donors\ndf_positive = data[(data['amount'] &gt; 0) & data['treatment'].notnull()]\n\n# Run regression\nX = sm.add_constant(df_positive['treatment'])\ny = df_positive['amount']\nmodel = sm.OLS(y, X).fit()\n\nprint(model.summary())\n\nResults\n\nIntercept (control group mean donation): $45.54\nTreatment coefficient: -1.668, p = 0.561\n\n\nAmong those who donated, individuals in the treatment group gave $1.67 less on average than those in the control group. However, this difference is not statistically significant (p = 0.561), and the confidence interval includes both negative and positive values (-7.31 to +3.97). This means that while the direction of the estimate is slightly negative, we have no evidence to conclude that the treatment caused people to give more or less, once they had already decided to donate.\nSo we do two bar chart to show the distribution directly. The histograms below display the distribution of donation amounts among individuals who made a donation, separately for the treatment and control groups. Each plot includes a red dashed line indicating the sample mean.\n\n\n\nDonation Amounts\n\n\nFrom the plots, we observe that:\n\nBoth groups are highly right-skewed: most donors give between $10–$50, but a small number give substantially more (some over $200).\nThe control group has a slightly higher mean donation ($45.54) compared to the treatment group ($43.87).\nThe two distributions are fairly similar in shape, with the treatment group having a marginally heavier tail but not substantially so.\n\nThis observation is consistent with our previous regression analysis (run on donors only), where the treatment group donated $1.67 less on average, but the difference was not statistically significant (p = 0.561).\nWhile the treatment had a positive effect on donation likelihood, it did not lead to higher donation amounts among those who chose to give. In fact, the treatment group donated slightly less on average.\nThis reinforces the interpretation that the matching grant offer may influence whether someone donates, but does not significantly affect how much they donate, once they decide to give.\n\n\nSimulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\n\nLaw of Large Numbers\nNext we want to simulate the cumulative average of differences in donation amounts between treatment and control groups.\nThis helps us visualize how a sample average stabilizes as the number of samples increases.\n\n\n\nCumulative Average of Donation Differences\n\n\n\n\n\nSimulation Code\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Filter for positive donations\ncontrol = data[(data['treatment'] == 0) & (data['amount'] &gt; 0)]['amount'].values\ntreatment = data[(data['treatment'] == 1) & (data['amount'] &gt; 0)]['amount'].values\n\n# Simulate draws\nnp.random.seed(42)\ndraws_control = np.random.choice(control, 100000, replace=True)\ndraws_treatment = np.random.choice(treatment, 10000, replace=True)\n\n# Calculate differences\ndifferences = draws_treatment - draws_control[:10000]\n\n# Compute cumulative average\ncumulative_avg = np.cumsum(differences) / np.arange(1, len(differences) + 1)\n\n# Plot\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, label='Cumulative Average of Differences', color='steelblue')\nplt.axhline(np.mean(treatment) - np.mean(control), color='red', linestyle='--', label='True Mean Difference')\nplt.title('Cumulative Average of Donation Differences (Treatment - Control)')\nplt.xlabel('Number of Simulated Pairs')\nplt.ylabel('Cumulative Average Difference ($)')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\nThis simulation illustrates how sample averages behave as we increase the number of observations. Initially, the cumulative average of differences is highly unstable, with large fluctuations. But as more pairs are sampled, the line converges toward the true mean difference, indicated by the red dashed line.\nThis is a direct demonstration of the Law of Large Numbers: as the number of samples increases, the sample mean gets closer to the population mean.\nIn this case, the simulation confirms that although there is considerable variation with small samples, the overall average difference in donations between the treatment and control groups stabilizes close to the true effect — which in our case is slightly negative.\n\n\nCentral Limit Theorem\nTo understand how sample size affects the precision and stability of estimated treatment effects, we simulate four sets of experiments with different sample sizes.\nFor each sample size (50, 200, 500, 1000), we:\n\nDraw n random samples from both the treatment and control distributions\nCompute the average donation difference (treatment - control)\nRepeat this process 1000 times\nPlot the distribution (histogram) of the 1000 average differences\n\n\n\n\nDifferent Sample Size Simulation\n\n\n\n\nSimulation Code\n\n# Filter: only positive donation amounts\ncontrol = data[(data['treatment'] == 0) & (data['amount'] &gt; 0)]['amount'].values\ntreatment = data[(data['treatment'] == 1) & (data['amount'] &gt; 0)]['amount'].values\n\nsample_sizes = [50, 200, 500, 1000]\nn_simulations = 1000\n\nplt.figure(figsize=(20, 4))\nfor i, size in enumerate(sample_sizes):\n    diffs = []\n    for _ in range(n_simulations):\n        c = np.random.choice(control, size, replace=True)\n        t = np.random.choice(treatment, size, replace=True)\n        diffs.append(np.mean(t) - np.mean(c))\n\n    plt.subplot(1, 4, i + 1)\n    plt.hist(diffs, bins=30, color='skyblue', edgecolor='black')\n    plt.axvline(x=0, color='red', linestyle='--', label='Zero Line')\n    plt.title(f'Sample size = {size}')\n    plt.xlabel('Mean Difference ($)')\n    plt.ylabel('Frequency')\n    plt.legend()\n\nplt.tight_layout()\nplt.show()\nAs sample size increases: - The distribution of estimated treatment effects becomes narrower and more concentrated - At small sample sizes (like 50), the distribution is wide, and zero is near the center, indicating a high degree of uncertainty - At larger sample sizes (like 1000), the distribution is tighter, and zero lies closer to the edge of the distribution, suggesting a more stable and possibly significant treatment effect\nThis simulation highlights how larger sample sizes reduce variance and help us better detect true effects.\nLarger samples lead to more precise and stable estimates of the treatment effect"
  }
]